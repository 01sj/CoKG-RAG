#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
LangGraph RAG ä¸»å…¥å£

å®Œå…¨å¤åˆ¶åŸ hybrid_rag_query.py çš„ main å‡½æ•°é€»è¾‘ï¼Œ
åªæ˜¯å°†æ‰§è¡Œæ–¹å¼ä»çº¿æ€§æ”¹ä¸ºå›¾ç»“æ„
"""

import json
import os
import sys
import time
import logging
import argparse
import numpy as np
from datetime import datetime
from typing import List, Dict

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# å¯¼å…¥åŸå§‹æ¨¡å—
from hybrid_rag_query import (
    HybridLegalRAG,
    setup_logging,
    VECTOR_DB_PATH,
    COLLECTION_NAME,
    KG_WORKING_DIR,
    EMBEDDING_MODEL,
    TOP_K,
    CORRELATION_THRESHOLD,
    DEVICE
)

# å¯¼å…¥ LangGraph æ¨¡å—
from state import create_initial_state
from workflow import create_rag_workflow, visualize_workflow


def main():
    """
    ä¸»å‡½æ•° - ä¸åŸç‰ˆæœ¬å®Œå…¨ä¸€è‡´çš„å‚æ•°å’Œé€»è¾‘
    """
    parser = argparse.ArgumentParser(description="æ··åˆRAGæ£€ç´¢ç³»ç»Ÿ (LangGraphç‰ˆæœ¬)")
    
    # æ•°æ®è·¯å¾„
    parser.add_argument(
        "--input",
        type=str,
        default="datasets/query_social.json",
        help="è¾“å…¥æŸ¥è¯¢æ•°æ®é›†è·¯å¾„"
    )
    parser.add_argument(
        "--output",
        type=str,
        default=None,
        help="è¾“å‡ºç»“æœè·¯å¾„ï¼ˆé»˜è®¤ä¸ºè¾“å…¥æ–‡ä»¶å_langgraph_pred.jsonï¼‰"
    )
    
    # å‘é‡æ•°æ®åº“é…ç½®
    parser.add_argument(
        "--vector-db",
        type=str,
        default=VECTOR_DB_PATH,
        help="Milvuså‘é‡æ•°æ®åº“è·¯å¾„"
    )
    parser.add_argument(
        "--collection",
        type=str,
        default=COLLECTION_NAME,
        help="Collectionåç§°"
    )
    
    # çŸ¥è¯†å›¾è°±é…ç½®
    parser.add_argument(
        "--kg-dir",
        type=str,
        default=KG_WORKING_DIR,
        help="çŸ¥è¯†å›¾è°±å·¥ä½œç›®å½•"
    )
    
    # æ¨¡å‹é…ç½®
    parser.add_argument(
        "--embedding-model",
        type=str,
        default=EMBEDDING_MODEL,
        help="Embeddingæ¨¡å‹åç§°"
    )
    parser.add_argument(
        "--llm-model",
        type=str,
        default="/newdatad/WHH/MyEmoHH/models/Qwen2-7B-Instruct",
        help="LLMæ¨¡å‹è·¯å¾„"
    )
    
    # æ£€ç´¢å‚æ•°
    parser.add_argument(
        "--top-k",
        type=int,
        default=TOP_K,
        help="æ£€ç´¢Top-K"
    )
    parser.add_argument(
        "--threshold",
        type=float,
        default=CORRELATION_THRESHOLD,
        help="ç›¸å…³ç³»æ•°é˜ˆå€¼"
    )
    parser.add_argument(
        "--alpha",
        type=float,
        default=0.7,
        help="æ··åˆæƒé‡alphaï¼ˆ0-1ï¼‰ï¼Œæ¨è0.7è¡¨ç¤º70%%è¯­ä¹‰+30%%BM25"
    )
    
    # LLMå‚æ•°
    parser.add_argument("--tp", type=int, default=1, help="tensor_parallel_size")
    parser.add_argument("--gpu-mem-util", type=float, default=0.75, help="GPUæ˜¾å­˜å ç”¨æ¯”ä¾‹")
    parser.add_argument("--max-model-len", type=int, default=4096, help="æœ€å¤§æ¨¡å‹åºåˆ—é•¿åº¦")
    parser.add_argument("--max-new-tokens", type=int, default=1024, help="æœ€å¤§ç”Ÿæˆtokenæ•°")
    parser.add_argument("--temperature", type=float, default=0.3, help="é‡‡æ ·æ¸©åº¦")
    parser.add_argument("--top-p", type=float, default=0.9, help="top_pé‡‡æ ·")
    
    # å…¶ä»–å‚æ•°
    parser.add_argument("--device", type=str, default=DEVICE, help="è®¾å¤‡ï¼ˆcpu/cudaï¼‰")
    parser.add_argument("--log-dir", type=str, default="logs", help="æ—¥å¿—ç›®å½•")
    parser.add_argument("--visualize", action="store_true", help="ç”Ÿæˆå·¥ä½œæµå¯è§†åŒ–å›¾")
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—
    logger, log_file = setup_logging(args.log_dir)
    logger.info("æ··åˆRAGæ£€ç´¢ç³»ç»Ÿå¯åŠ¨ (LangGraphç‰ˆæœ¬)")
    logger.info(f"ğŸ”§ GPUé…ç½®: ä½¿ç”¨ {len(os.environ.get('CUDA_VISIBLE_DEVICES', '0').split(','))} å¼ GPUå¡")
    logger.info(f"   - CUDA_VISIBLE_DEVICES: {os.environ.get('CUDA_VISIBLE_DEVICES', 'æœªè®¾ç½®')}")
    logger.info(f"   - Tensor Parallel Size: {args.tp}")
    logger.info(f"è¾“å…¥æ–‡ä»¶: {args.input}")
    
    # ç¡®å®šè¾“å‡ºè·¯å¾„
    if args.output is None:
        input_dir = os.path.dirname(args.input) or "."
        input_name = os.path.splitext(os.path.basename(args.input))[0]
        args.output = os.path.join(input_dir, f"{input_name}_langgraph_pred.json")
    
    logger.info(f"è¾“å‡ºæ–‡ä»¶: {args.output}")
    
    # åˆå§‹åŒ–æ··åˆRAGç³»ç»Ÿï¼ˆå¤ç”¨åŸå§‹ç±»ï¼‰
    llm_params = {
        "tp": args.tp,
        "gpu_mem_util": args.gpu_mem_util,
        "max_model_len": args.max_model_len,
        "max_new_tokens": args.max_new_tokens,
        "temperature": args.temperature,
        "top_p": args.top_p,
    }
    
    rag_system = HybridLegalRAG(
        vector_db_path=args.vector_db,
        collection_name=args.collection,
        kg_working_dir=args.kg_dir,
        embedding_model_name=args.embedding_model,
        device=args.device,
        llm_model_path=args.llm_model,
        llm_params=llm_params
    )
    
    # åˆ›å»º LangGraph å·¥ä½œæµ
    logger.info("æ­£åœ¨æ„å»º LangGraph å·¥ä½œæµ...")
    app = create_rag_workflow(rag_system)
    logger.info("âœ… LangGraph å·¥ä½œæµæ„å»ºå®Œæˆ")
    
    # å¯è§†åŒ–å·¥ä½œæµï¼ˆå¯é€‰ï¼‰
    if args.visualize:
        visualize_workflow(app)
    
    # åŠ è½½æŸ¥è¯¢æ•°æ®é›†
    logger.info(f"æ­£åœ¨åŠ è½½æŸ¥è¯¢æ•°æ®é›†: {args.input}")
    with open(args.input, 'r', encoding='utf-8') as f:
        queries = json.load(f)
    
    logger.info(f"å…±åŠ è½½ {len(queries)} æ¡æŸ¥è¯¢")
    
    # æ‰¹é‡å¤„ç†
    results = []
    total_start_time = time.time()
    
    for i, item in enumerate(queries):
        logger.info(f"\nå¤„ç†ç¬¬ {i+1}/{len(queries)} æ¡æŸ¥è¯¢")
        
        query = item.get("question", "").strip()
        instruction = item.get("instruction", "").strip()
        
        if not query:
            logger.warning("æŸ¥è¯¢ä¸ºç©ºï¼Œè·³è¿‡")
            new_item = dict(item)
            new_item["prediction"] = ""
            new_item["bm25_top1_score"] = 10.0
            new_item["overlap_ratio"] = 0.0
            new_item["top3_overlap"] = 0.0
            new_item["combined_score"] = 0.0
            new_item["used_kg"] = False
            results.append(new_item)
            continue
        
        # æ‰§è¡Œæ£€ç´¢å’Œå›ç­”ï¼ˆä½¿ç”¨ LangGraphï¼‰
        try:
            item_start_time = time.time()
            
            # åˆ›å»ºåˆå§‹çŠ¶æ€
            initial_state = create_initial_state(
                query=query,
                instruction=instruction,
                original_item=item,
                top_k=args.top_k,
                alpha=args.alpha,
                correlation_threshold=args.threshold
            )
            
            # æ‰§è¡Œå·¥ä½œæµ
            final_state = app.invoke(initial_state)
            
            # è®¡ç®—æ€»è€—æ—¶
            elapsed_time = time.time() - item_start_time
            
            # ä¿å­˜ç»“æœï¼ˆæ ¼å¼ä¸åŸç‰ˆæœ¬å®Œå…¨ä¸€è‡´ï¼‰
            new_item = dict(item)
            new_item["prediction"] = final_state["answer"]
            
            # æ ¸å¿ƒæŒ‡æ ‡
            new_item["bm25_top1_score"] = final_state["bm25_top1_score"]
            new_item["overlap_ratio"] = final_state["overlap_ratio"]
            new_item["top3_overlap"] = final_state["top3_overlap"]
            new_item["combined_score"] = final_state["combined_score"]
            
            # ç»Ÿä¸€å¤æ‚åº¦è¯„ä¼°æŒ‡æ ‡
            new_item["question_type"] = final_state["question_type"]
            new_item["question_nature_complexity"] = final_state["question_nature_complexity"]
            new_item["retrieval_inconsistency"] = final_state["retrieval_inconsistency"]
            new_item["final_complexity"] = final_state["final_complexity"]
            new_item["evaluation_layer"] = final_state["evaluation_layer"]
            
            new_item["used_kg"] = final_state["use_kg"]
            new_item["elapsed_time"] = elapsed_time
            
            # æ·»åŠ æ­¥éª¤è€—æ—¶ï¼ˆLangGraphç‰¹æœ‰ï¼‰
            new_item["step_times"] = final_state.get("step_times", {})
            
            results.append(new_item)
            
        except Exception as e:
            logger.error(f"å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            
            new_item = dict(item)
            new_item["prediction"] = f"å¤„ç†å¤±è´¥: {str(e)}"
            new_item["bm25_top1_score"] = 10.0
            new_item["overlap_ratio"] = 0.0
            new_item["top3_overlap"] = 0.0
            new_item["combined_score"] = 0.0
            new_item["used_kg"] = False
            results.append(new_item)
    
    total_elapsed_time = time.time() - total_start_time
    
    # ä¿å­˜ç»“æœ
    logger.info(f"\næ­£åœ¨ä¿å­˜ç»“æœåˆ°: {args.output}")
    with open(args.output, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    # ç»Ÿè®¡ä¿¡æ¯ï¼ˆä¸åŸç‰ˆæœ¬å®Œå…¨ä¸€è‡´ï¼‰
    total_queries = len(results)
    kg_used_count = sum(1 for r in results if r.get("used_kg", False))
    
    # è®¡ç®—æ ¸å¿ƒæŒ‡æ ‡çš„å¹³å‡å€¼
    avg_bm25_top1 = np.mean([r.get("bm25_top1_score", 10.0) for r in results])
    avg_overlap_ratio = np.mean([r.get("overlap_ratio", 0.0) for r in results])
    avg_top3_overlap = np.mean([r.get("top3_overlap", 0.0) for r in results])
    avg_combined_score = np.mean([r.get("combined_score", 0.0) for r in results])
    avg_final_complexity = np.mean([r.get("final_complexity", 0.0) for r in results])
    
    logger.info(f"\n{'='*60}")
    logger.info("å¤„ç†å®Œæˆï¼(LangGraphç‰ˆæœ¬)")
    logger.info(f"æ€»æŸ¥è¯¢æ•°: {total_queries}")
    logger.info(f"æ€»è€—æ—¶: {total_elapsed_time:.2f}ç§’")
    logger.info(f"å¹³å‡è€—æ—¶: {total_elapsed_time/total_queries:.2f}ç§’/æ¡")
    logger.info(f"ä½¿ç”¨çŸ¥è¯†å›¾è°±: {kg_used_count} ({kg_used_count/total_queries*100:.1f}%)")
    logger.info(f"\nğŸ“Š æ ¸å¿ƒæŒ‡æ ‡ç»Ÿè®¡:")
    logger.info(f"{'='*60}")
    logger.info(f"1ï¸âƒ£ BM25 Top1åˆ†æ•°:")
    logger.info(f"   - å¹³å‡å€¼: {avg_bm25_top1:.3f}")
    logger.info(f"2ï¸âƒ£ æ–‡æ¡£é‡å ç‡:")
    logger.info(f"   - å¹³å‡å€¼: {avg_overlap_ratio:.3f}")
    logger.info(f"3ï¸âƒ£ Top-3é‡å ç‡:")
    logger.info(f"   - å¹³å‡å€¼: {avg_top3_overlap:.3f}")
    logger.info(f"4ï¸âƒ£ æœ€ç»ˆå¤æ‚åº¦:")
    logger.info(f"   - å¹³å‡å€¼: {avg_final_complexity:.3f}")
    logger.info(f"\nğŸ“ˆ ç»¼åˆè¯„åˆ†:")
    logger.info(f"   - å¹³å‡ç»¼åˆå¤æ‚åº¦: {avg_combined_score:.3f}")
    logger.info(f"{'='*60}")
    logger.info(f"ç»“æœå·²ä¿å­˜åˆ°: {args.output}")
    logger.info(f"æ—¥å¿—å·²ä¿å­˜åˆ°: {log_file}")
    logger.info(f"{'='*60}")


if __name__ == "__main__":
    main()
