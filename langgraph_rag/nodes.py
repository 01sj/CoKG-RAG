#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
LangGraph èŠ‚ç‚¹å‡½æ•°

æ¯ä¸ªèŠ‚ç‚¹å¯¹åº”åŸæµç¨‹ä¸­çš„ä¸€ä¸ªæ­¥éª¤ï¼Œå¤ç”¨åŸ HybridLegalRAG ç±»çš„æ–¹æ³•
"""

import time
import logging
from typing import Dict
from state import RAGState

logger = logging.getLogger(__name__)


def query_rewrite_node(state: RAGState, rag_system) -> Dict:
    """
    èŠ‚ç‚¹0: æŸ¥è¯¢é‡å†™
    
    å¯¹åº”åŸæµç¨‹çš„ rewrite_query_for_consistency æ–¹æ³•
    """
    start_time = time.time()
    
    logger.info(f"\n{'='*60}")
    logger.info(f"ğŸ” æŸ¥è¯¢: {state['query'][:50]}...")
    if state['instruction']:
        logger.info(f"ğŸ“‹ æŒ‡ä»¤: {state['instruction'][:50]}...")
    logger.info(f"{'='*60}")
    
    # æ£€æµ‹æ˜¯å¦ä¸ºåˆ†ç±»ä»»åŠ¡
    is_classification = rag_system._is_classification_task(state['instruction'])
    
    # åˆ†ç±»ä»»åŠ¡è°ƒæ•´å‚æ•°
    if is_classification:
        logger.info(f"   ğŸ·ï¸ æ£€æµ‹åˆ°åˆ†ç±»ä»»åŠ¡ï¼Œä½¿ç”¨ä¼˜åŒ–å‚æ•°")
        top_k = 15
        alpha = 0.75
        threshold = 0.55
        
        logger.info(f"   - Top-K: {state['top_k']} â†’ {top_k}")
        logger.info(f"   - Alpha: {state['alpha']} â†’ {alpha}")
        logger.info(f"   - é˜ˆå€¼: {state['threshold']} â†’ {threshold}")
        
        # æ·»åŠ åˆ†ç±»ç¤ºä¾‹
        instruction = rag_system._add_classification_examples(
            state['instruction'], 
            state['query']
        )
        logger.info(f"   âœ… å·²æ·»åŠ åˆ†ç±»ç¤ºä¾‹åˆ°æŒ‡ä»¤")
        
        # æ£€æµ‹åŒ»ç–—çº çº·
        is_medical, medical_confidence = rag_system._detect_medical_dispute(state['query'])
        if is_medical and medical_confidence > 0.6:
            logger.info(f"   âš•ï¸ æ£€æµ‹åˆ°å¯èƒ½çš„åŒ»ç–—çº çº·ï¼ˆç½®ä¿¡åº¦: {medical_confidence:.2f}ï¼‰")
            instruction += "\n\nã€ç‰¹åˆ«æç¤ºã€‘è¯¥é—®é¢˜å¯èƒ½æ¶‰åŠåŒ»ç–—çº çº·ï¼Œè¯·ä»”ç»†åˆ¤æ–­æ˜¯å¦ä¸ºåŒ»ç–—æœºæ„çš„åŒ»ç–—è¡Œä¸ºå¯¼è‡´çš„æŸå®³ã€‚"
    else:
        top_k = state['top_k']
        alpha = state['alpha']
        threshold = state['threshold']  # ä½¿ç”¨é…ç½®çš„é˜ˆå€¼ï¼ˆé»˜è®¤0.35ï¼‰
        instruction = state['instruction']
    
    # æŸ¥è¯¢é‡å†™
    rewritten_query = rag_system.rewrite_query_for_consistency(
        state['query'], 
        instruction
    )
    
    elapsed = time.time() - start_time
    
    return {
        "rewritten_query": rewritten_query,
        "instruction": instruction,
        "is_classification": is_classification,
        "top_k": top_k,
        "alpha": alpha,
        "threshold": threshold,
        "step_times": {"query_rewrite": elapsed}
    }


def semantic_search_node(state: RAGState, rag_system) -> Dict:
    """
    èŠ‚ç‚¹1: è¯­ä¹‰å‘é‡æ£€ç´¢
    
    å¯¹åº”åŸæµç¨‹çš„ semantic_search æ–¹æ³•
    """
    start_time = time.time()
    
    semantic_results = rag_system.semantic_search(
        state['query'],
        top_k=state['top_k'],
        rewritten_query=state['rewritten_query']
    )
    
    elapsed = time.time() - start_time
    
    return {
        "semantic_results": semantic_results,
        "step_times": {"semantic_search": elapsed}
    }


def bm25_search_node(state: RAGState, rag_system) -> Dict:
    """
    èŠ‚ç‚¹2: BM25æ£€ç´¢
    
    å¯¹åº”åŸæµç¨‹çš„ bm25_search æ–¹æ³•
    """
    start_time = time.time()
    
    bm25_results = rag_system.bm25_search(
        state['query'],
        top_k=state['top_k'],
        rewritten_query=state['rewritten_query']
    )
    
    elapsed = time.time() - start_time
    
    return {
        "bm25_results": bm25_results,
        "step_times": {"bm25_search": elapsed}
    }


def evaluation_node(state: RAGState, rag_system) -> Dict:
    """
    èŠ‚ç‚¹3: æ™ºèƒ½è¯„ä¼°ä¸å†³ç­–
    
    å¯¹åº”åŸæµç¨‹çš„ï¼š
    - compare_independent_rankings
    - create_hybrid_results
    - _rerank_and_select
    """
    start_time = time.time()
    
    # æ­¥éª¤3: æ¯”è¾ƒä¸¤ç§æ£€ç´¢ç»“æœ
    metrics = rag_system.compare_independent_rankings(
        state['semantic_results'],
        state['bm25_results'],
        state['query']
    )
    
    # æ­¥éª¤4: åˆ›å»ºæ··åˆæ£€ç´¢ç»“æœ
    logger.info(f"æ­¥éª¤4: åˆ›å»ºæ··åˆæ£€ç´¢ç»“æœ (alpha={state['alpha']})...")
    hybrid_results = rag_system.create_hybrid_results(
        state['semantic_results'],
        state['bm25_results'],
        alpha=state['alpha']
    )
    logger.info(f"   âœ… æ··åˆæ£€ç´¢å®Œæˆï¼Œå…± {len(hybrid_results)} ä¸ªæ–‡æ¡£")
    top3_scores = [f"{r['hybrid_score']:.3f}" for r in hybrid_results[:3]]
    logger.info(f"   Top3 æ··åˆåˆ†æ•°: {top3_scores}")
    
    # æ­¥éª¤4.5: é‡æ’åºå¹¶åŠ¨æ€é€‰æ‹©æ–‡æ¡£
    logger.info(f"æ­¥éª¤4.5: é‡æ’åºå¹¶é€‰æ‹©æœ€ç›¸å…³æ–‡æ¡£...")
    max_context_docs = 12 if state['is_classification'] else 10
    
    reranked_results, selected_count = rag_system._rerank_and_select(
        hybrid_results,
        state['query'],
        metrics['combined_score'],
        is_simple=(metrics['combined_score'] < state['threshold']),  # åè½¬ï¼šå¤æ‚åº¦ä½=ç®€å•
        max_docs=max_context_docs
    )
    logger.info(f"   âœ… é‡æ’åºå®Œæˆï¼Œé€‰æ‹© {selected_count} ä¸ªæœ€ç›¸å…³æ–‡æ¡£")
    
    # åˆ¤æ–­æ˜¯å¦ä½¿ç”¨KGï¼ˆåè½¬é€»è¾‘ï¼šå¤æ‚åº¦è¯„ä¼°ï¼‰
    combined_score = metrics['combined_score']
    threshold = state['threshold']
    
    if combined_score >= threshold:
        logger.info(f"âœ“ æœ€ç»ˆå¤æ‚åº¦ {combined_score:.3f} >= {threshold}")
        logger.info(f"   â†’ é—®é¢˜å¤æ‚ï¼Œéœ€è¦KGè¾…åŠ©")
        use_kg = True
    else:
        logger.info(f"âœ— æœ€ç»ˆå¤æ‚åº¦ {combined_score:.3f} < {threshold}")
        logger.info(f"   â†’ é—®é¢˜ç®€å•ï¼Œä½¿ç”¨ä¼ ç»ŸRAG")
        use_kg = False
    
    elapsed = time.time() - start_time
    
    return {
        "hybrid_results": hybrid_results,
        "selected_docs": reranked_results,
        "bm25_top1_score": metrics['bm25_top1_score'],
        "overlap_ratio": metrics['overlap_ratio'],
        "top3_overlap": metrics['top3_overlap'],
        "combined_score": metrics['combined_score'],
        "question_type": metrics.get('question_type', 'unknown'),
        "question_nature_complexity": metrics.get('question_nature_complexity', 0.0),
        "retrieval_inconsistency": metrics.get('retrieval_inconsistency', 0.0),
        "final_complexity": metrics.get('final_complexity', 0.0),
        "evaluation_layer": metrics.get('evaluation_layer', 0),
        "metrics": metrics,
        "use_kg": use_kg,
        "step_times": {"evaluation": elapsed}
    }


def kg_search_node(state: RAGState, rag_system) -> Dict:
    """
    èŠ‚ç‚¹4: çŸ¥è¯†å›¾è°±æ£€ç´¢
    
    å¯¹åº”åŸæµç¨‹çš„ kg_search æ–¹æ³•
    ä»…åœ¨ use_kg=True æ—¶æ‰§è¡Œ
    """
    start_time = time.time()
    
    kg_context = rag_system.kg_search(state['query'], top_k=state['top_k'])
    
    elapsed = time.time() - start_time
    
    return {
        "kg_context": kg_context,
        "step_times": {"kg_search": elapsed}
    }


def answer_generation_node(state: RAGState, rag_system) -> Dict:
    """
    èŠ‚ç‚¹5: ç­”æ¡ˆç”Ÿæˆ
    
    å¯¹åº”åŸæµç¨‹çš„ generate_answer æ–¹æ³•
    """
    start_time = time.time()
    
    # æ„å»ºä¸Šä¸‹æ–‡
    if state['use_kg']:
        # èåˆå‘é‡æ£€ç´¢å’ŒçŸ¥è¯†å›¾è°±ç»“æœ
        vector_context = "\n\n".join([
            f"ã€æ–‡æ¡£{i+1}ã€‘{r['source_name']}\n{r['text']}"
            for i, r in enumerate(state['selected_docs'])
        ])
        
        final_context = f"""
## å‘é‡æ£€ç´¢ç»“æœ

{vector_context}

## çŸ¥è¯†å›¾è°±æ£€ç´¢ç»“æœ

{state['kg_context']}
"""
    else:
        # åªä½¿ç”¨å‘é‡æ£€ç´¢ç»“æœ
        final_context = "\n\n".join([
            f"ã€æ–‡æ¡£{i+1}ã€‘{r['source_name']}\n{r['text']}"
            for i, r in enumerate(state['selected_docs'])
        ])
    
    # ç”Ÿæˆç­”æ¡ˆ
    answer = rag_system.generate_answer(
        state['query'],
        final_context,
        state['instruction'],
        state['use_kg'],
        semantic_results=state['semantic_results'],
        bm25_results=state['bm25_results']
    )
    
    elapsed = time.time() - start_time
    
    logger.info(f"\n{'='*60}")
    logger.info(f"âœ… å®Œæˆï¼")
    logger.info(f"{'='*60}\n")
    
    return {
        "answer": answer,
        "step_times": {"answer_generation": elapsed}
    }
