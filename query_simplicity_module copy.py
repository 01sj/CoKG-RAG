"""
æŸ¥è¯¢å¤æ‚åº¦è¯„ä¼°æ¨¡å—ï¼ˆ5ç»´åº¦ç‰ˆæœ¬ï¼‰

æ ¸å¿ƒç†å¿µï¼š
- åˆ©ç”¨LLMå°†å¤æ‚é—®é¢˜æ‹†åˆ†ä¸ºå­é—®é¢˜
- åŸºäºå­é—®é¢˜è¯„ä¼°5ä¸ªç»´åº¦çš„å¤æ‚åº¦
- 5ä¸ªç»´åº¦ä¸æ£€ç´¢ä¸ä¸€è‡´æ€§äº’è¡¥ï¼Œå…±åŒå†³ç­–æ˜¯å¦ä½¿ç”¨KG

äº”ä¸ªæ ¸å¿ƒç»´åº¦ï¼ˆè¯„ä¼°é—®é¢˜æœ¬è´¨ï¼‰ï¼š
1. æ¨ç†é“¾é•¿åº¦ (Reasoning Chain Length, RCL)
2. çŸ¥è¯†æ•´åˆéœ€æ±‚ (Knowledge Integration Requirement, KIR)
3. å…³ç³»æ¨ç†å¤æ‚åº¦ (Relational Reasoning Complexity, RRC)
4. é¢†åŸŸè·¨åº¦ (Domain Span, DS)
5. æ¡ä»¶çº¦æŸå¯†åº¦ (Conditional Constraint Density, CCD)

æ£€ç´¢ç»´åº¦ï¼ˆè¯„ä¼°æ£€ç´¢éš¾åº¦ï¼‰ï¼š
- æ£€ç´¢ä¸ä¸€è‡´æ€§ (Retrieval Inconsistency, RI)


è¡¡é‡çš„ç®€å•åº¦
"""

import re
import numpy as np
from typing import List, Dict, Optional, Tuple

# ==================== LLMå­é—®é¢˜æ‹†åˆ† ====================

def decompose_query_with_llm(query: str, llm=None, sampling_params=None) -> Dict:
    """
    ä½¿ç”¨LLMå°†å¤æ‚é—®é¢˜æ‹†åˆ†ä¸ºå­é—®é¢˜
    
    Args:
        query: åŸå§‹æŸ¥è¯¢
        llm: LLMæ¨¡å‹å®ä¾‹ï¼ˆå¯é€‰ï¼‰
        sampling_params: LLMé‡‡æ ·å‚æ•°ï¼ˆå¯é€‰ï¼‰
        
    Returns:
        åŒ…å«å­é—®é¢˜åˆ—è¡¨å’Œæ‹†åˆ†ä¿¡æ¯çš„å­—å…¸
    """
    # å¦‚æœæ²¡æœ‰æä¾›LLMï¼Œè¿”å›åŸé—®é¢˜ä½œä¸ºå”¯ä¸€å­é—®é¢˜
    if llm is None:
        return {
            'sub_questions': [query],
            'num_sub_questions': 1,
            'decomposition_success': False,
            'reason': 'LLMæœªæä¾›'
        }
    
    # æ„å»ºæ‹†åˆ†æç¤ºè¯
    decomposition_prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ³•å¾‹é—®é¢˜åˆ†æä¸“å®¶ã€‚è¯·å°†ä»¥ä¸‹æ³•å¾‹å’¨è¯¢é—®é¢˜æ‹†åˆ†ä¸ºå¤šä¸ªå­é—®é¢˜ã€‚

æ‹†åˆ†è§„åˆ™ï¼š
1. å¦‚æœé—®é¢˜å¾ˆç®€å•ï¼ˆå¦‚æŸ¥è¯¢æ³•æ¡å†…å®¹ã€æ¦‚å¿µå®šä¹‰ï¼‰ï¼Œç›´æ¥è¿”å›"æ— éœ€æ‹†åˆ†"
2. å¦‚æœé—®é¢˜å¤æ‚ï¼ˆå¦‚åœºæ™¯æ¨ç†ã€å¤šæ¡ä»¶åˆ¤æ–­ï¼‰ï¼Œæ‹†åˆ†ä¸º2-5ä¸ªå­é—®é¢˜
3. å­é—®é¢˜åº”è¯¥æ˜¯ç‹¬ç«‹çš„ã€å¯ä»¥å•ç‹¬å›ç­”çš„
4. å­é—®é¢˜åº”è¯¥è¦†ç›–åŸé—®é¢˜çš„æ‰€æœ‰å…³é”®è¦ç´ 

åŸå§‹é—®é¢˜ï¼š{query}

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼ˆä¸¥æ ¼éµå®ˆæ ¼å¼ï¼‰ï¼š
ã€æ˜¯å¦éœ€è¦æ‹†åˆ†ã€‘æ˜¯/å¦
ã€å­é—®é¢˜åˆ—è¡¨ã€‘
1. å­é—®é¢˜1
2. å­é—®é¢˜2
...

å¦‚æœä¸éœ€è¦æ‹†åˆ†ï¼Œåªè¾“å‡ºï¼š
ã€æ˜¯å¦éœ€è¦æ‹†åˆ†ã€‘å¦
ã€åŸå› ã€‘ç®€å•é—®é¢˜ï¼Œæ— éœ€æ‹†åˆ†"""
    
    try:
        # ä½¿ç”¨LLMç”Ÿæˆæ‹†åˆ†
        outputs = llm.generate([decomposition_prompt], sampling_params)
        
        if not outputs or not outputs[0].outputs:
            return {
                'sub_questions': [query],
                'num_sub_questions': 1,
                'decomposition_success': False,
                'reason': 'LLMè¿”å›ç©º'
            }
        
        response = outputs[0].outputs[0].text.strip()
        
        # è§£æå“åº”
        if 'ã€æ˜¯å¦éœ€è¦æ‹†åˆ†ã€‘å¦' in response or 'æ— éœ€æ‹†åˆ†' in response:
            return {
                'sub_questions': [query],
                'num_sub_questions': 1,
                'decomposition_success': True,
                'reason': 'ç®€å•é—®é¢˜ï¼Œæ— éœ€æ‹†åˆ†'
            }
        
        # æå–å­é—®é¢˜
        sub_questions = []
        lines = response.split('\n')
        for line in lines:
            line = line.strip()
            # åŒ¹é… "1. xxx" æˆ– "1ã€xxx" æ ¼å¼
            match = re.match(r'^\d+[.ã€]\s*(.+)$', line)
            if match:
                sub_q = match.group(1).strip()
                if sub_q and len(sub_q) > 3:  # è¿‡æ»¤å¤ªçŸ­çš„
                    sub_questions.append(sub_q)
        
        # éªŒè¯æ‹†åˆ†ç»“æœ
        if len(sub_questions) == 0:
            # æ‹†åˆ†å¤±è´¥ï¼Œè¿”å›åŸé—®é¢˜
            return {
                'sub_questions': [query],
                'num_sub_questions': 1,
                'decomposition_success': False,
                'reason': 'æ‹†åˆ†å¤±è´¥ï¼Œæœªæå–åˆ°å­é—®é¢˜'
            }
        elif len(sub_questions) == 1:
            # åªæœ‰ä¸€ä¸ªå­é—®é¢˜ï¼Œå¯èƒ½æ˜¯ç®€å•é—®é¢˜
            return {
                'sub_questions': sub_questions,
                'num_sub_questions': 1,
                'decomposition_success': True,
                'reason': 'ç®€å•é—®é¢˜æˆ–å•ä¸€é—®é¢˜'
            }
        else:
            # æˆåŠŸæ‹†åˆ†ä¸ºå¤šä¸ªå­é—®é¢˜
            return {
                'sub_questions': sub_questions,
                'num_sub_questions': len(sub_questions),
                'decomposition_success': True,
                'reason': f'æˆåŠŸæ‹†åˆ†ä¸º{len(sub_questions)}ä¸ªå­é—®é¢˜'
            }
    
    except Exception as e:
        # å¼‚å¸¸æƒ…å†µï¼Œè¿”å›åŸé—®é¢˜
        return {
            'sub_questions': [query],
            'num_sub_questions': 1,
            'decomposition_success': False,
            'reason': f'æ‹†åˆ†å¼‚å¸¸: {str(e)}'
        }


# ==================== 5ä¸ªæ ¸å¿ƒç»´åº¦è¯„ä¼° ====================

def measure_reasoning_chain_length(sub_questions: List[str], original_query: str) -> Dict:
    """
    ç»´åº¦1: æ¨ç†é“¾é•¿åº¦ (Reasoning Chain Length, RCL)
    
    åŸºäºå­é—®é¢˜æ•°é‡è¯„ä¼°æ¨ç†æ­¥éª¤çš„é•¿åº¦
    
    è¯„åˆ†è§„åˆ™ï¼š
    - 1ä¸ªå­é—®é¢˜: 0.0 (å•è·³)
    - 2ä¸ªå­é—®é¢˜: 0.3 (ä¸¤è·³)
    - 3ä¸ªå­é—®é¢˜: 0.6 (ä¸‰è·³)
    - 4ä¸ªå­é—®é¢˜: 0.8 (å››è·³)
    - 5+ä¸ªå­é—®é¢˜: 1.0 (å¤šè·³)
    
    Args:
        sub_questions: å­é—®é¢˜åˆ—è¡¨
        original_query: åŸå§‹æŸ¥è¯¢
        
    Returns:
        åŒ…å«è¯„ä¼°ç»“æœçš„å­—å…¸
    """
    num_sub = len(sub_questions)
    
    # è®¡ç®—åˆ†æ•°
    if num_sub == 1:
        score = 0.0
        level = "å•è·³"
    elif num_sub == 2:
        score = 0.3
        level = "ä¸¤è·³"
    elif num_sub == 3:
        score = 0.6
        level = "ä¸‰è·³"
    elif num_sub == 4:
        score = 0.8
        level = "å››è·³"
    else:
        score = 1.0
        level = "å¤šè·³"
    
    return {
        'dimension': 'æ¨ç†é“¾é•¿åº¦',
        'score': score,
        'level': level,
        'num_sub_questions': num_sub,
        'description': f'{num_sub}ä¸ªå­é—®é¢˜ï¼Œ{level}æ¨ç†'
    }


def measure_knowledge_integration_requirement(sub_questions: List[str], original_query: str) -> Dict:
    """
    ç»´åº¦2: çŸ¥è¯†æ•´åˆéœ€æ±‚ (Knowledge Integration Requirement, KIR)
    
    è¯„ä¼°éœ€è¦æ•´åˆçš„çŸ¥è¯†ç‚¹æ•°é‡
    
    æ”¹è¿›ï¼šè€ƒè™‘å­é—®é¢˜æ•°é‡ä½œä¸ºçŸ¥è¯†æ•´åˆçš„æŒ‡æ ‡
    - å¤šä¸ªå­é—®é¢˜æœ¬èº«å°±æ„å‘³ç€éœ€è¦æ•´åˆå¤šä¸ªçŸ¥è¯†ç‚¹
    
    è¯„åˆ†è§„åˆ™ï¼š
    - æ£€æµ‹æ³•å¾‹æ¦‚å¿µ/æ³•æ¡æ•°é‡
    - è€ƒè™‘å­é—®é¢˜æ•°é‡ï¼ˆæ¯ä¸ªå­é—®é¢˜ä»£è¡¨ä¸€ä¸ªéœ€è¦æ•´åˆçš„çŸ¥è¯†ç‚¹ï¼‰
    
    Args:
        sub_questions: å­é—®é¢˜åˆ—è¡¨
        original_query: åŸå§‹æŸ¥è¯¢
        
    Returns:
        åŒ…å«è¯„ä¼°ç»“æœçš„å­—å…¸
    """
    # æ³•å¾‹æ¦‚å¿µå…³é”®è¯
    legal_concepts = [
        'åŠ³åŠ¨åˆåŒ', 'åŠ³åŠ¨å…³ç³»', 'å·¥ä¼¤', 'ç¤¾ä¼šä¿é™©', 'å…»è€ä¿é™©', 'åŒ»ç–—ä¿é™©',
        'å¤±ä¸šä¿é™©', 'å·¥ä¼¤ä¿é™©', 'ç”Ÿè‚²ä¿é™©', 'ä½æˆ¿å…¬ç§¯é‡‘',
        'åŠ³åŠ¨æŠ¥é…¬', 'åŠ ç­è´¹', 'ç»æµè¡¥å¿', 'èµ”å¿', 'è¡¥å¿',
        'ç”¨äººå•ä½', 'åŠ³åŠ¨è€…', 'èŒå·¥', 'å‘˜å·¥',
        'è§£é™¤', 'ç»ˆæ­¢', 'è¾é€€', 'è¾èŒ',
        'å·¥ä½œæ—¶é—´', 'ä¼‘æ¯ä¼‘å‡', 'å¹´ä¼‘å‡', 'ç—…å‡', 'äº§å‡',
        'åŠ³åŠ¨äº‰è®®', 'ä»²è£', 'è¯‰è®¼',
        'å®‰å…¨ç”Ÿäº§', 'èŒä¸šç—…', 'å·¥ä¼¤è®¤å®š',
        'é€€ä¼‘', 'å…»è€é‡‘', 'é€€ä¼‘é‡‘',
        'æœªæˆå¹´äºº', 'å¦‡å¥³', 'è€å¹´äºº', 'æ®‹ç–¾äºº',
    ]
    
    # æ³•æ¡æ¨¡å¼
    law_patterns = [
        r'ç¬¬\d+æ¡',
        r'ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾]+æ¡',
        r'ã€Š.+?ã€‹',
    ]
    
    # ç»Ÿè®¡çŸ¥è¯†ç‚¹
    knowledge_points = set()
    
    # ä»åŸå§‹æŸ¥è¯¢ä¸­æå–
    for concept in legal_concepts:
        if concept in original_query:
            knowledge_points.add(concept)
    
    for pattern in law_patterns:
        matches = re.findall(pattern, original_query)
        knowledge_points.update(matches)
    
    # ä»å­é—®é¢˜ä¸­æå–
    for sub_q in sub_questions:
        for concept in legal_concepts:
            if concept in sub_q:
                knowledge_points.add(concept)
        
        for pattern in law_patterns:
            matches = re.findall(pattern, sub_q)
            knowledge_points.update(matches)
    
    num_knowledge_points = len(knowledge_points)
    
    # ğŸ”§ æ”¹è¿›ï¼šå¦‚æœæœ‰å¤šä¸ªå­é—®é¢˜ï¼Œè¯´æ˜éœ€è¦æ•´åˆå¤šä¸ªçŸ¥è¯†ç‚¹
    # æ¯ä¸ªå­é—®é¢˜è‡³å°‘ä»£è¡¨ä¸€ä¸ªéœ€è¦æ•´åˆçš„çŸ¥è¯†ç‚¹
    num_sub = len(sub_questions)
    if num_sub > 1:
        # å­é—®é¢˜æ•°é‡ä¹Ÿç®—ä½œçŸ¥è¯†æ•´åˆçš„æŒ‡æ ‡
        effective_knowledge_points = max(num_knowledge_points, num_sub)
    else:
        effective_knowledge_points = num_knowledge_points
    
    # è®¡ç®—åˆ†æ•°ï¼ˆåŸºäºæœ‰æ•ˆçŸ¥è¯†ç‚¹æ•°ï¼‰
    if effective_knowledge_points <= 1:
        score = 0.0
        level = "å•ä¸€çŸ¥è¯†ç‚¹"
    elif effective_knowledge_points == 2:
        score = 0.4
        level = "å°‘é‡çŸ¥è¯†ç‚¹"
    elif effective_knowledge_points == 3:
        score = 0.7
        level = "ä¸­ç­‰çŸ¥è¯†ç‚¹"
    elif effective_knowledge_points == 4:
        score = 0.9
        level = "è¾ƒå¤šçŸ¥è¯†ç‚¹"
    else:
        score = 1.0
        level = "å¤§é‡çŸ¥è¯†ç‚¹"
    
    return {
        'dimension': 'çŸ¥è¯†æ•´åˆéœ€æ±‚',
        'score': score,
        'level': level,
        'num_knowledge_points': num_knowledge_points,
        'num_sub_questions': num_sub,
        'effective_knowledge_points': effective_knowledge_points,
        'knowledge_points': list(knowledge_points)[:5],  # åªæ˜¾ç¤ºå‰5ä¸ª
        'description': f'{effective_knowledge_points}ä¸ªçŸ¥è¯†ç‚¹ï¼ˆ{num_knowledge_points}ä¸ªæ¦‚å¿µ+{num_sub}ä¸ªå­é—®é¢˜ï¼‰ï¼Œ{level}'
    }


def measure_relational_reasoning_complexity(sub_questions: List[str], original_query: str) -> Dict:
    """
    ç»´åº¦3: å…³ç³»æ¨ç†å¤æ‚åº¦ (Relational Reasoning Complexity, RRC)
    
    è¯„ä¼°æ¶‰åŠçš„å…³ç³»ç±»å‹æ•°é‡ï¼ˆä»å±ã€å› æœã€æ¡ä»¶ã€å¯¹æ¯”ç­‰ï¼‰
    
    æ”¹è¿›ï¼šåœºæ™¯æ¨ç†é—®é¢˜é€šå¸¸æ¶‰åŠå¤šç§éšå«å…³ç³»
    
    è¯„åˆ†è§„åˆ™ï¼š
    - æ£€æµ‹é—®é¢˜ä¸­çš„å…³ç³»ç±»å‹
    - åœºæ™¯æ¨ç†é—®é¢˜è‡ªåŠ¨å¢åŠ å…³ç³»å¤æ‚åº¦
    - å…³ç³»ç±»å‹è¶Šå¤šï¼Œæ¨ç†è¶Šå¤æ‚
    
    Args:
        sub_questions: å­é—®é¢˜åˆ—è¡¨
        original_query: åŸå§‹æŸ¥è¯¢
        
    Returns:
        åŒ…å«è¯„ä¼°ç»“æœçš„å­—å…¸
    """
    # å…³ç³»ç±»å‹å…³é”®è¯
    relation_types = {
        'ä»å±å…³ç³»': ['å±äº', 'åŒ…å«', 'å½’å±', 'åŒ…æ‹¬åœ¨'],
        'å› æœå…³ç³»': ['å› ä¸º', 'ç”±äº', 'å¯¼è‡´', 'é€ æˆ', 'å¼•èµ·', 'æ‰€ä»¥', 'ç»“æœ'],
        'æ¡ä»¶å…³ç³»': ['å¦‚æœ', 'æ»¡è¶³', 'ç¬¦åˆ', 'æ¡ä»¶', 'å‰æ', 'å¿…é¡»', 'éœ€è¦'],
        'å¯¹æ¯”å…³ç³»': ['åŒºåˆ«', 'å¯¹æ¯”', 'æ¯”è¾ƒ', 'ä¸åŒ', 'ç›¸åŒ'],
        'æ—¶åºå…³ç³»': ['ä¹‹å‰', 'ä¹‹å', 'å…ˆ', 'å', 'æ¥ç€', 'ç„¶å'],
        'ç¨‹åºå…³ç³»': ['æµç¨‹', 'æ­¥éª¤', 'ç¨‹åº', 'è¿‡ç¨‹', 'æ€ä¹ˆåŠ'],
        'åˆ¤æ–­å…³ç³»': ['ç®—ä¸ç®—', 'æ˜¯å¦', 'èƒ½å¦', 'å¯ä»¥å—', 'è®¤å®šä¸º', 'ç®—', 'æ˜¯ä¸æ˜¯'],
    }
    
    # ç»Ÿè®¡å…³ç³»ç±»å‹
    detected_relations = set()
    all_text = original_query + ' ' + ' '.join(sub_questions)
    
    for relation_type, keywords in relation_types.items():
        for keyword in keywords:
            if keyword in all_text:
                detected_relations.add(relation_type)
                break
    
    # ğŸ”§ æ”¹è¿›ï¼šæ£€æµ‹åœºæ™¯æ¨ç†é—®é¢˜
    scenario_keywords = ['æˆ‘', 'ä»–', 'å¥¹', 'å…¬å¸', 'å•ä½', 'å·¥å‚', 'åœºæ™¯', 'æƒ…å†µ']
    has_scenario = any(kw in original_query for kw in scenario_keywords)
    
    # åœºæ™¯æ¨ç†é—®é¢˜é€šå¸¸æ¶‰åŠå¤šç§éšå«å…³ç³»
    if has_scenario and len(sub_questions) > 1:
        # åœºæ™¯æ¨ç†è‡³å°‘æ¶‰åŠï¼šæ¡ä»¶å…³ç³»ã€åˆ¤æ–­å…³ç³»
        detected_relations.add('æ¡ä»¶å…³ç³»ï¼ˆéšå«ï¼‰')
        if 'åˆ¤æ–­å…³ç³»' not in detected_relations:
            detected_relations.add('åˆ¤æ–­å…³ç³»ï¼ˆéšå«ï¼‰')
    
    num_relations = len(detected_relations)
    
    # è®¡ç®—åˆ†æ•°
    if num_relations == 0:
        score = 0.0
        level = "æ— å…³ç³»æ¨ç†"
    elif num_relations == 1:
        score = 0.3
        level = "å•ä¸€å…³ç³»"
    elif num_relations == 2:
        score = 0.6
        level = "åŒé‡å…³ç³»"
    elif num_relations == 3:
        score = 0.8
        level = "å¤šé‡å…³ç³»"
    else:
        score = 1.0
        level = "å¤æ‚å…³ç³»ç½‘ç»œ"
    
    return {
        'dimension': 'å…³ç³»æ¨ç†å¤æ‚åº¦',
        'score': score,
        'level': level,
        'num_relations': num_relations,
        'relation_types': list(detected_relations),
        'has_scenario': has_scenario,
        'description': f'{num_relations}ç§å…³ç³»ç±»å‹ï¼Œ{level}'
    }


def measure_domain_span(sub_questions: List[str], original_query: str) -> Dict:
    """
    ç»´åº¦4: é¢†åŸŸè·¨åº¦ (Domain Span, DS)
    
    è¯„ä¼°æ¶‰åŠçš„æ³•å¾‹é¢†åŸŸæ•°é‡
    
    æ”¹è¿›ï¼šå·¥ä¼¤ç›¸å…³é—®é¢˜é€šå¸¸æ¶‰åŠå¤šä¸ªé¢†åŸŸ
    
    è¯„åˆ†è§„åˆ™ï¼š
    - æ£€æµ‹æ¶‰åŠçš„æ³•å¾‹é¢†åŸŸ
    - å·¥ä¼¤é—®é¢˜é€šå¸¸æ¶‰åŠåŠ³åŠ¨æ³•+å·¥ä¼¤ä¿é™©+ç¤¾ä¼šä¿é™©
    - é¢†åŸŸè¶Šå¤šï¼Œè·¨åº¦è¶Šå¤§
    
    Args:
        sub_questions: å­é—®é¢˜åˆ—è¡¨
        original_query: åŸå§‹æŸ¥è¯¢
        
    Returns:
        åŒ…å«è¯„ä¼°ç»“æœçš„å­—å…¸
    """
    # æ³•å¾‹é¢†åŸŸå…³é”®è¯
    legal_domains = {
        'åŠ³åŠ¨æ³•': ['åŠ³åŠ¨åˆåŒ', 'åŠ³åŠ¨å…³ç³»', 'åŠ³åŠ¨æŠ¥é…¬', 'åŠ ç­', 'è¾é€€', 'åŠ³åŠ¨äº‰è®®', 'ç”¨äººå•ä½', 'åŠ³åŠ¨è€…'],
        'ç¤¾ä¼šä¿é™©æ³•': ['ç¤¾ä¼šä¿é™©', 'å…»è€ä¿é™©', 'åŒ»ç–—ä¿é™©', 'å¤±ä¸šä¿é™©', 'ç”Ÿè‚²ä¿é™©', 'ç¤¾ä¿'],
        'å·¥ä¼¤ä¿é™©': ['å·¥ä¼¤', 'å·¥ä¼¤è®¤å®š', 'å·¥ä¼¤èµ”å¿', 'èŒä¸šç—…', 'å·¥ä¼¤å¾…é‡'],
        'æœªæˆå¹´äººä¿æŠ¤æ³•': ['æœªæˆå¹´äºº', 'å„¿ç«¥', 'å­¦ç”Ÿ', 'ç›‘æŠ¤äºº', 'æœªæ»¡18'],
        'å¦‡å¥³æƒç›Šä¿éšœæ³•': ['å¦‡å¥³', 'å¥³èŒå·¥', 'äº§å‡', 'ç”Ÿè‚²', 'æ€§åˆ«æ­§è§†'],
        'è€å¹´äººæƒç›Šä¿éšœæ³•': ['è€å¹´äºº', 'å…»è€', 'èµ¡å…»', 'é€€ä¼‘'],
        'å®‰å…¨ç”Ÿäº§æ³•': ['å®‰å…¨ç”Ÿäº§', 'ç”Ÿäº§å®‰å…¨', 'å®‰å…¨äº‹æ•…', 'å®‰å…¨è´£ä»»'],
        'åˆåŒæ³•': ['åˆåŒ', 'åè®®', 'è¿çº¦', 'åˆåŒçº çº·'],
    }
    
    # ç»Ÿè®¡é¢†åŸŸ
    detected_domains = set()
    all_text = original_query + ' ' + ' '.join(sub_questions)
    
    for domain, keywords in legal_domains.items():
        for keyword in keywords:
            if keyword in all_text:
                detected_domains.add(domain)
                break
    
    # ğŸ”§ æ”¹è¿›ï¼šå·¥ä¼¤é—®é¢˜é€šå¸¸æ¶‰åŠå¤šä¸ªé¢†åŸŸ
    if 'å·¥ä¼¤ä¿é™©' in detected_domains:
        # å·¥ä¼¤é—®é¢˜é€šå¸¸ä¹Ÿæ¶‰åŠåŠ³åŠ¨æ³•å’Œç¤¾ä¼šä¿é™©æ³•
        # æ£€æŸ¥æ˜¯å¦æœ‰åŠ³åŠ¨ç›¸å…³å†…å®¹
        labor_keywords = ['åŠ³åŠ¨', 'ç”¨äººå•ä½', 'åŠ³åŠ¨è€…', 'èŒå·¥', 'å·¥å‚', 'å…¬å¸', 'å•ä½', 'ä¸Šç­', 'å·¥ä½œ']
        if any(kw in all_text for kw in labor_keywords):
            detected_domains.add('åŠ³åŠ¨æ³•')
        
        # å·¥ä¼¤ä¿é™©æœ¬èº«å°±æ˜¯ç¤¾ä¼šä¿é™©çš„ä¸€éƒ¨åˆ†
        # åªè¦æœ‰å·¥ä¼¤ï¼Œå°±æ¶‰åŠç¤¾ä¼šä¿é™©æ³•
        detected_domains.add('ç¤¾ä¼šä¿é™©æ³•')
    
    num_domains = len(detected_domains)
    
    # è®¡ç®—åˆ†æ•°
    if num_domains <= 1:
        score = 0.0
        level = "å•ä¸€é¢†åŸŸ"
    elif num_domains == 2:
        score = 0.5
        level = "è·¨ä¸¤ä¸ªé¢†åŸŸ"
    elif num_domains == 3:
        score = 0.8
        level = "è·¨ä¸‰ä¸ªé¢†åŸŸ"
    else:
        score = 1.0
        level = "è·¨å¤šä¸ªé¢†åŸŸ"
    
    return {
        'dimension': 'é¢†åŸŸè·¨åº¦',
        'score': score,
        'level': level,
        'num_domains': num_domains,
        'domains': list(detected_domains),
        'description': f'{num_domains}ä¸ªæ³•å¾‹é¢†åŸŸï¼Œ{level}'
    }


def measure_conditional_constraint_density(sub_questions: List[str], original_query: str) -> Dict:
    """
    ç»´åº¦5: æ¡ä»¶çº¦æŸå¯†åº¦ (Conditional Constraint Density, CCD)
    
    è¯„ä¼°åŒ…å«çš„çº¦æŸæ¡ä»¶æ•°é‡ï¼ˆå¹´é¾„ã€æ—¶é—´ã€é‡‘é¢ã€åœ°ç‚¹ç­‰ï¼‰
    
    è¯„åˆ†è§„åˆ™ï¼š
    - æ£€æµ‹å…·ä½“çš„çº¦æŸæ¡ä»¶
    - æ¡ä»¶è¶Šå¤šï¼Œçº¦æŸè¶Šå¯†é›†
    
    Args:
        sub_questions: å­é—®é¢˜åˆ—è¡¨
        original_query: åŸå§‹æŸ¥è¯¢
        
    Returns:
        åŒ…å«è¯„ä¼°ç»“æœçš„å­—å…¸
    """
    all_text = original_query + ' ' + ' '.join(sub_questions)
    
    # çº¦æŸæ¡ä»¶æ¨¡å¼
    constraint_patterns = {
        'å¹´é¾„': r'\d+å²|\d+å‘¨å²|æœªæ»¡\d+|æ»¡\d+',
        'æ—¶é—´': r'\d+å¹´|\d+ä¸ªæœˆ|\d+æ—¥|\d+å¤©|\d+å°æ—¶',
        'é‡‘é¢': r'\d+å…ƒ|\d+ä¸‡|\d+åƒ',
        'æ•°é‡': r'\d+æ¬¡|\d+ä¸ª|\d+äºº',
        'æ¯”ä¾‹': r'\d+%|ç™¾åˆ†ä¹‹\d+',
    }
    
    # ç»Ÿè®¡çº¦æŸæ¡ä»¶
    constraints = []
    for constraint_type, pattern in constraint_patterns.items():
        matches = re.findall(pattern, all_text)
        if matches:
            constraints.extend([(constraint_type, m) for m in matches])
    
    num_constraints = len(constraints)
    
    # è®¡ç®—åˆ†æ•°
    if num_constraints == 0:
        score = 0.0
        level = "æ— çº¦æŸæ¡ä»¶"
    elif num_constraints == 1:
        score = 0.3
        level = "å•ä¸€çº¦æŸ"
    elif num_constraints == 2:
        score = 0.6
        level = "åŒé‡çº¦æŸ"
    elif num_constraints == 3:
        score = 0.8
        level = "å¤šé‡çº¦æŸ"
    else:
        score = 1.0
        level = "å¯†é›†çº¦æŸ"
    
    return {
        'dimension': 'æ¡ä»¶çº¦æŸå¯†åº¦',
        'score': score,
        'level': level,
        'num_constraints': num_constraints,
        'constraints': constraints[:5],  # åªæ˜¾ç¤ºå‰5ä¸ª
        'description': f'{num_constraints}ä¸ªçº¦æŸæ¡ä»¶ï¼Œ{level}'
    }


# ==================== æ£€ç´¢ä¸€è‡´æ€§è¯„ä¼°ï¼ˆä¿ç•™åŸæœ‰é€»è¾‘ï¼‰====================

def calculate_retrieval_consistency_confidence(
    bm25_top1_score: float,
    overlap_ratio: float,
    top3_overlap: float
) -> Dict:
    """
    è®¡ç®—æ£€ç´¢ä¸€è‡´æ€§ç½®ä¿¡åº¦ (Retrieval Consistency Confidence, RCC)
    
    è¿™æ˜¯ç¬¬6ä¸ªç»´åº¦ï¼Œè¯„ä¼°æ£€ç´¢ç³»ç»Ÿçš„èƒ½åŠ›ï¼Œä¸å‰5ä¸ªç»´åº¦äº’è¡¥
    
    Args:
        bm25_top1_score: BM25 Top1åˆ†æ•°
        overlap_ratio: æ–‡æ¡£é‡å ç‡
        top3_overlap: Top3é‡å ç‡
        
    Returns:
        åŒ…å«è¯„ä¼°ç»“æœçš„å­—å…¸
    """
    # æŸ¥è¯¢ç®€å•æ€§æŒ‡æ•° (QSI) - åŸºäºBM25
    query_simplicity_index = 1.0 / (1.0 + np.exp(0.5 * (bm25_top1_score - 12.5)))
    
    # æ£€ç´¢å·®å¼‚æ€§æŒ‡æ•° (RDI) - åŸºäºé‡å ç‡
    retrieval_divergence = 1.0 - (0.7 * overlap_ratio + 0.3 * top3_overlap)
    
    # ç®€å•é—®é¢˜ç½®ä¿¡åº¦ (ä½¿ç”¨ç«äº‰å‡½æ•°)
    alpha = 1.5
    beta = 0.3
    epsilon = 1e-10
    
    simple_evidence = (query_simplicity_index ** alpha) * (retrieval_divergence ** beta) + epsilon
    complex_evidence = ((1 - query_simplicity_index) ** alpha) * ((1 - retrieval_divergence) ** beta) + epsilon
    
    retrieval_consistency_confidence = simple_evidence / (simple_evidence + complex_evidence)
    
    # åå¤„ç†ï¼šBM25è¾ƒé«˜ä¸”overlapè¾ƒä½æ—¶çš„æƒ©ç½š
    if bm25_top1_score > 10.0 and overlap_ratio < 0.3:
        bm25_penalty = min(0.95, (bm25_top1_score - 10.0) / 6.0)
        overlap_bonus = overlap_ratio / 0.3
        final_penalty = bm25_penalty * (1.0 - overlap_bonus)
        retrieval_consistency_confidence = retrieval_consistency_confidence * (1.0 - final_penalty)
    
    retrieval_consistency_confidence = np.clip(retrieval_consistency_confidence, 0, 1)
    
    return {
        'dimension': 'æ£€ç´¢ä¸€è‡´æ€§ç½®ä¿¡åº¦',
        'score': retrieval_consistency_confidence,
        'query_simplicity_index': query_simplicity_index,
        'retrieval_divergence': retrieval_divergence,
        'description': f'æ£€ç´¢ä¸€è‡´æ€§: {retrieval_consistency_confidence:.3f}'
    }


# ==================== ç»¼åˆå†³ç­– ====================

def calculate_five_dimension_score(
    query: str,
    sub_questions: List[str],
    bm25_top1_score: float,
    overlap_ratio: float,
    top3_overlap: float
) -> Dict:
    """
    åŸºäº5ç»´åº¦+æ£€ç´¢ä¸€è‡´æ€§çš„ç»¼åˆè¯„åˆ†
    
    å†³ç­–é€»è¾‘ï¼š
    1. è¯„ä¼°5ä¸ªç»´åº¦ï¼ˆé—®é¢˜æœ¬è´¨ï¼‰
    2. è¯„ä¼°æ£€ç´¢ä¸€è‡´æ€§ï¼ˆæ£€ç´¢èƒ½åŠ›ï¼‰
    3. ç»¼åˆè¯„åˆ† = 50% * é—®é¢˜æœ¬è´¨ + 50% * æ£€ç´¢æ•ˆæœ
    4. ç»´åº¦è¦†ç›–åˆ¤æ–­ï¼šâ‰¥3ä¸ªç»´åº¦ â†’ KGï¼Œâ‰¤2ä¸ªç»´åº¦ â†’ ä¼ ç»ŸRAG
    
    Args:
        query: åŸå§‹æŸ¥è¯¢
        sub_questions: å­é—®é¢˜åˆ—è¡¨
        bm25_top1_score: BM25 Top1åˆ†æ•°
        overlap_ratio: æ–‡æ¡£é‡å ç‡
        top3_overlap: Top3é‡å ç‡
        
    Returns:
        åŒ…å«æ‰€æœ‰è¯„ä¼°ç»“æœçš„å­—å…¸
    """
    # ========== è¯„ä¼°5ä¸ªç»´åº¦ ==========
    dim1 = measure_reasoning_chain_length(sub_questions, query)
    dim2 = measure_knowledge_integration_requirement(sub_questions, query)
    dim3 = measure_relational_reasoning_complexity(sub_questions, query)
    dim4 = measure_domain_span(sub_questions, query)
    dim5 = measure_conditional_constraint_density(sub_questions, query)
    
    # ç»Ÿè®¡è¦†ç›–çš„ç»´åº¦æ•°é‡ï¼ˆåˆ†æ•° > 0.3 è§†ä¸ºè¦†ç›–ï¼‰
    threshold = 0.3
    covered_dimensions = []
    if dim1['score'] > threshold:
        covered_dimensions.append(dim1['dimension'])
    if dim2['score'] > threshold:
        covered_dimensions.append(dim2['dimension'])
    if dim3['score'] > threshold:
        covered_dimensions.append(dim3['dimension'])
    if dim4['score'] > threshold:
        covered_dimensions.append(dim4['dimension'])
    if dim5['score'] > threshold:
        covered_dimensions.append(dim5['dimension'])
    
    num_covered = len(covered_dimensions)
    
    # é—®é¢˜æœ¬è´¨å¤æ‚åº¦ï¼ˆ5ä¸ªç»´åº¦çš„åŠ æƒå¹³å‡ï¼‰
    # æƒé‡ï¼šæ¨ç†é“¾(30%) + çŸ¥è¯†æ•´åˆ(25%) + å…³ç³»æ¨ç†(20%) + é¢†åŸŸè·¨åº¦(15%) + æ¡ä»¶çº¦æŸ(10%)
    question_complexity = (
        0.30 * dim1['score'] +
        0.25 * dim2['score'] +
        0.20 * dim3['score'] +
        0.15 * dim4['score'] +
        0.10 * dim5['score']
    )
    
    question_simplicity = 1.0 - question_complexity
    
    # ========== è¯„ä¼°æ£€ç´¢ä¸€è‡´æ€§ ==========
    rcc = calculate_retrieval_consistency_confidence(
        bm25_top1_score, overlap_ratio, top3_overlap
    )
    
    # ========== ç»¼åˆè¯„åˆ†è®¡ç®— ==========
    # é—®é¢˜å¤æ‚åº¦åˆ†å€¼ï¼š0-1ï¼Œè¶Šé«˜è¶Šå¤æ‚
    complexity_score = question_complexity
    
    # æ£€ç´¢ä¸€è‡´æ€§åˆ†å€¼ï¼š0-1ï¼Œè¶Šé«˜è¶Šä¸€è‡´ï¼ˆè¯´æ˜æ£€ç´¢æ•ˆæœå¥½ï¼‰
    retrieval_score = rcc['score']
    
    # ç»¼åˆè¯„åˆ†ï¼šé—®é¢˜å¤æ‚åº¦(50%) + æ£€ç´¢ä¸ä¸€è‡´æ€§(50%)
    # æ³¨æ„ï¼šæ£€ç´¢ä¸€è‡´æ€§é«˜ â†’ ç®€å•é—®é¢˜ï¼Œæ‰€ä»¥ç”¨ (1 - retrieval_score) è¡¨ç¤ºæ£€ç´¢çš„å¤æ‚æ€§
    # ç»¼åˆè¯„åˆ†è¶Šé«˜ â†’ è¶Šéœ€è¦KG
    final_score = 0.5 * complexity_score + 0.5 * (1.0 - retrieval_score)
    
    # ========== å†³ç­–è§„åˆ™ï¼ˆåŸºäºç»¼åˆè¯„åˆ†é˜ˆå€¼ï¼‰==========
    # é˜ˆå€¼è®¾ç½®ï¼š0.4
    # - ç»¼åˆè¯„åˆ† â‰¥ 0.4 â†’ ä½¿ç”¨KGï¼ˆé—®é¢˜å¤æ‚æˆ–æ£€ç´¢æ•ˆæœå·®ï¼‰
    # - ç»¼åˆè¯„åˆ† < 0.4 â†’ ä½¿ç”¨ä¼ ç»ŸRAGï¼ˆé—®é¢˜ç®€å•ä¸”æ£€ç´¢æ•ˆæœå¥½ï¼‰
    decision_threshold = 0.4
    
    if final_score >= decision_threshold:
        needs_kg = True
        reason = (
            f"éœ€è¦KGï¼šç»¼åˆè¯„åˆ†{final_score:.3f}â‰¥{decision_threshold} "
            f"(é—®é¢˜å¤æ‚åº¦{complexity_score:.3f} + æ£€ç´¢ä¸ä¸€è‡´æ€§{(1.0-retrieval_score):.3f})"
        )
    else:
        needs_kg = False
        reason = (
            f"ä½¿ç”¨ä¼ ç»ŸRAGï¼šç»¼åˆè¯„åˆ†{final_score:.3f}<{decision_threshold} "
            f"(é—®é¢˜å¤æ‚åº¦{complexity_score:.3f} + æ£€ç´¢ä¸ä¸€è‡´æ€§{(1.0-retrieval_score):.3f})"
        )
    
    return {
        # 5ä¸ªç»´åº¦è¯¦æƒ…
        'dimension_1_reasoning_chain': dim1,
        'dimension_2_knowledge_integration': dim2,
        'dimension_3_relational_reasoning': dim3,
        'dimension_4_domain_span': dim4,
        'dimension_5_conditional_constraint': dim5,
        
        # ç»´åº¦è¦†ç›–ç»Ÿè®¡
        'num_covered_dimensions': num_covered,
        'covered_dimensions': covered_dimensions,
        'coverage_threshold': threshold,
        
        # é—®é¢˜æœ¬è´¨è¯„åˆ†
        'question_complexity': round(question_complexity, 3),
        'question_simplicity': round(question_simplicity, 3),
        
        # æ£€ç´¢ä¸€è‡´æ€§
        'retrieval_consistency': rcc,
        
        # ç»¼åˆè¯„åˆ†ç»„æˆ
        'complexity_score': round(complexity_score, 3),
        'retrieval_score': round(retrieval_score, 3),
        'retrieval_inconsistency': round(1.0 - retrieval_score, 3),
        
        # ç»¼åˆè¯„åˆ†
        'final_score': round(final_score, 3),
        'decision_threshold': decision_threshold,
        
        # å†³ç­–ç»“æœ
        'needs_kg': needs_kg,
        'reason': reason,
    }


# ==================== æ–°ç‰ˆï¼šä¸‰å±‚è¯„ä¼°æ¶æ„ ====================

def classify_simple_question_type(query: str) -> Dict:
    """
    ç¬¬ä¸€å±‚ï¼šå¿«é€Ÿåˆ†ç±»ç®€å•é—®é¢˜ç±»å‹
    
    ç®€å•é—®é¢˜ç±»å‹åŠåŸºç¡€å¤æ‚åº¦ï¼š
    - æ³•æ¡æŸ¥è¯¢ (0.1): æŸ¥è¯¢å…·ä½“æ³•æ¡å†…å®¹
    - æ¦‚å¿µå®šä¹‰ (0.15): æŸ¥è¯¢æ³•å¾‹æ¦‚å¿µå®šä¹‰
    - ç®€å•åˆ—ä¸¾ (0.2): æŸ¥è¯¢ç®€å•çš„åˆ—è¡¨ä¿¡æ¯
    - å…ƒä¿¡æ¯ (0.2): æŸ¥è¯¢ç«‹æ³•ç›®çš„ã€é€‚ç”¨èŒƒå›´ç­‰
    
    Args:
        query: æŸ¥è¯¢æ–‡æœ¬
        
    Returns:
        åŒ…å«é—®é¢˜ç±»å‹å’ŒåŸºç¡€å¤æ‚åº¦çš„å­—å…¸
    """
    # æ³•æ¡æŸ¥è¯¢æ¨¡å¼
    law_article_patterns = [
        r'ç¬¬\d+æ¡',
        r'ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾]+æ¡',
        r'\d+æ¡(?!ä»¶)',
        r'ç¬¬\d+æ¬¾',
    ]
    has_article = any(re.search(p, query) for p in law_article_patterns)
    content_words = ['å†…å®¹', 'æ˜¯ä»€ä¹ˆ', 'è¯´çš„æ˜¯', 'è®²äº†ä»€ä¹ˆ', 'è§„å®š', 'å‘Šè¯‰æˆ‘']
    has_content_query = any(word in query for word in content_words)
    
    if has_article and has_content_query and 'åœºæ™¯' not in query:
        return {
            'type': 'æ³•æ¡æŸ¥è¯¢',
            'base_complexity': 0.1,
            'is_simple': True,
            'description': 'æŸ¥è¯¢å…·ä½“æ³•æ¡å†…å®¹'
        }
    
    # æ¦‚å¿µå®šä¹‰æ¨¡å¼
    concept_patterns = ['ä»€ä¹ˆæ˜¯', 'çš„å®šä¹‰', 'å®šä¹‰æ˜¯', 'æ¦‚å¿µæ˜¯', 'å«ä¹‰æ˜¯']
    if any(p in query for p in concept_patterns):
        return {
            'type': 'æ¦‚å¿µå®šä¹‰',
            'base_complexity': 0.15,
            'is_simple': True,
            'description': 'æŸ¥è¯¢æ³•å¾‹æ¦‚å¿µå®šä¹‰'
        }
    
    # ç®€å•åˆ—ä¸¾æ¨¡å¼ï¼ˆæ’é™¤éœ€è¦æ¨ç†çš„åˆ—ä¸¾ï¼‰
    enumeration_patterns = ['åŒ…æ‹¬å“ªäº›', 'åˆ†ä¸ºå“ªå‡ ç§', 'æœ‰å“ªäº›', 'æœ‰å‡ ç§']
    reasoning_words = ['ç®—', 'å±äº', 'è®¤å®šä¸º', 'åˆ¤æ–­']
    is_simple_enum = any(p in query for p in enumeration_patterns)
    needs_reasoning = any(w in query for w in reasoning_words)
    
    if is_simple_enum and not needs_reasoning:
        return {
            'type': 'ç®€å•åˆ—ä¸¾',
            'base_complexity': 0.2,
            'is_simple': True,
            'description': 'æŸ¥è¯¢ç®€å•çš„åˆ—è¡¨ä¿¡æ¯'
        }
    
    # å…ƒä¿¡æ¯æŸ¥è¯¢æ¨¡å¼
    meta_patterns = ['ç«‹æ³•ç›®çš„', 'ç«‹æ³•å®—æ—¨', 'é€‚ç”¨èŒƒå›´', 'é€‚ç”¨äºå“ªäº›']
    if any(p in query for p in meta_patterns):
        return {
            'type': 'å…ƒä¿¡æ¯',
            'base_complexity': 0.2,
            'is_simple': True,
            'description': 'æŸ¥è¯¢ç«‹æ³•ç›®çš„ã€é€‚ç”¨èŒƒå›´ç­‰'
        }
    
    # ä¸æ˜¯ç®€å•é—®é¢˜
    return {
        'type': 'å¤æ‚é—®é¢˜',
        'base_complexity': None,
        'is_simple': False,
        'description': 'éœ€è¦è¿›ä¸€æ­¥åˆ†ç±»'
    }


def classify_complex_question_type(query: str) -> Dict:
    """
    ç¬¬äºŒå±‚ï¼šå¤æ‚é—®é¢˜ç»†åˆ†ç±»å‹
    
    å¤æ‚é—®é¢˜ç±»å‹åŠåŸºç¡€å¤æ‚åº¦ï¼š
    - åœºæ™¯æ¨ç† (0.5): å…·ä½“åœºæ™¯çš„æ³•å¾‹åˆ¤æ–­
    - æ¡ä»¶åˆ¤æ–­ (0.45): åˆ¤æ–­æ˜¯å¦æ»¡è¶³æŸä¸ªæ³•å¾‹æ¡ä»¶
    - å¤šæ¡ä»¶ç»„åˆ (0.5): æ¶‰åŠå¤šä¸ªæ¡ä»¶çš„ç»¼åˆåˆ¤æ–­
    - æƒç›Šç»´æŠ¤ (0.55): æƒç›Šå—æŸåçš„æ•‘æµé€”å¾„
    - è·¨é¢†åŸŸ (0.6): æ¶‰åŠå¤šä¸ªæ³•å¾‹é¢†åŸŸ
    - å¤æ‚åˆ—ä¸¾ (0.4): éœ€è¦æ¨ç†åˆ¤æ–­çš„åˆ—ä¸¾
    
    Args:
        query: æŸ¥è¯¢æ–‡æœ¬
        
    Returns:
        åŒ…å«é—®é¢˜ç±»å‹å’ŒåŸºç¡€å¤æ‚åº¦çš„å­—å…¸
    """
    # åœºæ™¯æ¨ç†ï¼šåŒ…å«å…·ä½“åœºæ™¯æè¿°
    scenario_keywords = [
        'æˆ‘æ˜¯', 'æˆ‘å¦ˆ', 'æˆ‘çˆ¸', 'æœ¬äºº', 'ä¸‹ç­', 'è·¯ä¸Š', 'é€”ä¸­',
        'å…¬å¸', 'è€æ¿', 'å·¥å‚', 'è½¦é—´', 'å•ä½', 'å­¦ç”Ÿ', 'è€å¸ˆ', 'ç…¤çŸ¿', 'å…¬å›­', 'èŒå·¥', 'å‘˜å·¥'
    ]
    abstract_patterns = ['é€‚ç”¨äº', 'é€‚ç”¨èŒƒå›´', 'ç«‹æ³•ç›®çš„', 'åŒ…æ‹¬å“ªäº›']
    is_abstract = any(p in query for p in abstract_patterns)
    has_scenario = any(kw in query for kw in scenario_keywords)
    
    if has_scenario and not is_abstract:
        return {
            'type': 'åœºæ™¯æ¨ç†',
            'base_complexity': 0.5,
            'description': 'å…·ä½“åœºæ™¯çš„æ³•å¾‹åˆ¤æ–­',
            'dimension_weights': {
                'rcl': 0.35,  # æ¨ç†é“¾é•¿åº¦æƒé‡å¢åŠ 
                'kir': 0.25,
                'rrc': 0.25,  # å…³ç³»æ¨ç†æƒé‡å¢åŠ 
                'ds': 0.10,
                'ccd': 0.05
            }
        }
    
    # æ¡ä»¶åˆ¤æ–­ï¼šåˆ¤æ–­æ˜¯å¦æ»¡è¶³æŸä¸ªæ³•å¾‹æ¡ä»¶
    judgment_keywords = [
        'ç®—ä¸ç®—', 'æ˜¯å¦', 'èƒ½å¦', 'å¯ä»¥å—', 'åˆç†', 'åˆæ³•',
        'è¿æ³•', 'è¿èƒŒ', 'èƒ½èµ·è¯‰', 'èƒ½æŠ¥', 'è®¤å®šä¸º'
    ]
    polite_phrases = ['èƒ½å‘Šè¯‰', 'å¯ä»¥å‘Šè¯‰', 'è¯·å‘Šè¯‰']
    is_polite = any(phrase in query for phrase in polite_phrases)
    has_judgment = any(kw in query for kw in judgment_keywords)
    
    if has_judgment and not is_polite:
        return {
            'type': 'æ¡ä»¶åˆ¤æ–­',
            'base_complexity': 0.45,
            'description': 'åˆ¤æ–­æ˜¯å¦æ»¡è¶³æŸä¸ªæ³•å¾‹æ¡ä»¶',
            'dimension_weights': {
                'rcl': 0.25,
                'kir': 0.25,
                'rrc': 0.30,  # å…³ç³»æ¨ç†æƒé‡å¢åŠ 
                'ds': 0.15,
                'ccd': 0.05
            }
        }
    
    # å¤šæ¡ä»¶ç»„åˆï¼šæ¶‰åŠå¤šä¸ªå…·ä½“æ¡ä»¶
    numeric_conditions = len(re.findall(r'\d+å¹´|\d+å²|\d+ä¸ªæœˆ|\d+æ—¥|\d+å…ƒ', query))
    if numeric_conditions >= 2:
        return {
            'type': 'å¤šæ¡ä»¶ç»„åˆ',
            'base_complexity': 0.5,
            'description': 'æ¶‰åŠå¤šä¸ªæ¡ä»¶çš„ç»¼åˆåˆ¤æ–­',
            'dimension_weights': {
                'rcl': 0.30,
                'kir': 0.25,
                'rrc': 0.20,
                'ds': 0.10,
                'ccd': 0.15  # æ¡ä»¶çº¦æŸæƒé‡å¢åŠ 
            }
        }
    
    # æƒç›Šç»´æŠ¤ï¼šæƒç›Šå—æŸåçš„æ•‘æµé€”å¾„
    rights_keywords = ['æ‹–æ¬ ', 'è¾é€€', 'è¡¥å¿', 'èµ”å¿', 'æ¬ è–ª', 'ä¸å‘', 'ç»´æƒ']
    remedy_keywords = ['æ€ä¹ˆåŠ', 'åŠæ³•', 'é€”å¾„', 'èµ·è¯‰', 'ä»²è£', 'æŠ•è¯‰']
    has_rights_issue = any(kw in query for kw in rights_keywords)
    has_remedy_query = any(kw in query for kw in remedy_keywords)
    
    if has_rights_issue or has_remedy_query:
        return {
            'type': 'æƒç›Šç»´æŠ¤',
            'base_complexity': 0.55,
            'description': 'æƒç›Šå—æŸåçš„æ•‘æµé€”å¾„',
            'dimension_weights': {
                'rcl': 0.35,  # æ¨ç†é“¾é•¿åº¦æƒé‡å¢åŠ 
                'kir': 0.30,  # çŸ¥è¯†æ•´åˆæƒé‡å¢åŠ 
                'rrc': 0.20,
                'ds': 0.10,
                'ccd': 0.05
            }
        }
    
    # è·¨é¢†åŸŸï¼šæ¶‰åŠå¤šä¸ªæ³•å¾‹é¢†åŸŸ
    legal_domains = {
        'åŠ³åŠ¨æ³•': ['åŠ³åŠ¨åˆåŒ', 'åŠ³åŠ¨å…³ç³»', 'åŠ³åŠ¨æŠ¥é…¬', 'åŠ ç­', 'è¾é€€'],
        'ç¤¾ä¼šä¿é™©æ³•': ['ç¤¾ä¼šä¿é™©', 'å…»è€ä¿é™©', 'åŒ»ç–—ä¿é™©', 'å¤±ä¸šä¿é™©', 'ç”Ÿè‚²ä¿é™©'],
        'å·¥ä¼¤ä¿é™©': ['å·¥ä¼¤', 'å·¥ä¼¤è®¤å®š', 'å·¥ä¼¤èµ”å¿', 'èŒä¸šç—…'],
        'æœªæˆå¹´äººä¿æŠ¤æ³•': ['æœªæˆå¹´äºº', 'å„¿ç«¥', 'å­¦ç”Ÿ', 'ç›‘æŠ¤äºº'],
        'å¦‡å¥³æƒç›Šä¿éšœæ³•': ['å¦‡å¥³', 'å¥³èŒå·¥', 'äº§å‡', 'ç”Ÿè‚²'],
    }
    
    detected_domains = 0
    for domain, keywords in legal_domains.items():
        if any(kw in query for kw in keywords):
            detected_domains += 1
    
    if detected_domains >= 2:
        return {
            'type': 'è·¨é¢†åŸŸ',
            'base_complexity': 0.6,
            'description': 'æ¶‰åŠå¤šä¸ªæ³•å¾‹é¢†åŸŸ',
            'dimension_weights': {
                'rcl': 0.25,
                'kir': 0.30,  # çŸ¥è¯†æ•´åˆæƒé‡å¢åŠ 
                'rrc': 0.20,
                'ds': 0.20,  # é¢†åŸŸè·¨åº¦æƒé‡å¢åŠ 
                'ccd': 0.05
            }
        }
    
    # å¤æ‚åˆ—ä¸¾ï¼šéœ€è¦æ¨ç†åˆ¤æ–­çš„åˆ—ä¸¾
    enumeration_patterns = ['åŒ…æ‹¬å“ªäº›', 'åˆ†ä¸ºå“ªå‡ ç§', 'æœ‰å“ªäº›', 'æœ‰å‡ ç§']
    reasoning_words = ['ç®—', 'å±äº', 'è®¤å®šä¸º', 'åˆ¤æ–­']
    is_enum = any(p in query for p in enumeration_patterns)
    needs_reasoning = any(w in query for w in reasoning_words)
    
    if is_enum and needs_reasoning:
        return {
            'type': 'å¤æ‚åˆ—ä¸¾',
            'base_complexity': 0.4,
            'description': 'éœ€è¦æ¨ç†åˆ¤æ–­çš„åˆ—ä¸¾',
            'dimension_weights': {
                'rcl': 0.25,
                'kir': 0.30,  # çŸ¥è¯†æ•´åˆæƒé‡å¢åŠ 
                'rrc': 0.25,
                'ds': 0.15,
                'ccd': 0.05
            }
        }
    
    # é»˜è®¤ï¼šä¸€èˆ¬å¤æ‚é—®é¢˜
    return {
        'type': 'ä¸€èˆ¬å¤æ‚é—®é¢˜',
        'base_complexity': 0.45,
        'description': 'ä¸€èˆ¬å¤æ‚é—®é¢˜',
        'dimension_weights': {
            'rcl': 0.30,
            'kir': 0.25,
            'rrc': 0.20,
            'ds': 0.15,
            'ccd': 0.10
        }
    }


def calculate_question_nature_complexity(
    query: str,
    sub_questions: List[str],
    llm=None,
    sampling_params=None
) -> Dict:
    """
    è®¡ç®—é—®é¢˜æœ¬è´¨å¤æ‚åº¦ï¼ˆæ–°ç‰ˆï¼‰
    
    ä¸‰å±‚è¯„ä¼°æ¶æ„ï¼š
    1. ç¬¬ä¸€å±‚ï¼šå¿«é€Ÿåˆ†ç±»ç®€å•é—®é¢˜
    2. ç¬¬äºŒå±‚ï¼šå¤æ‚é—®é¢˜ç»†åˆ†ç±»å‹
    3. ç¬¬ä¸‰å±‚ï¼šäº”ç»´åº¦æ·±åº¦è¯„ä¼°
    
    æœ€ç»ˆå¤æ‚åº¦ = åŸºç¡€åˆ† Ã— 0.3 + äº”ç»´åº¦åŠ æƒåˆ† Ã— 0.7
    é—®é¢˜æœ¬è´¨å¤æ‚åº¦ = æœ€ç»ˆå¤æ‚åº¦ï¼ˆåˆ†æ•°è¶Šé«˜è¶Šå¤æ‚ï¼‰
    
    Args:
        query: åŸå§‹æŸ¥è¯¢
        sub_questions: å­é—®é¢˜åˆ—è¡¨
        llm: LLMæ¨¡å‹å®ä¾‹ï¼ˆå¯é€‰ï¼‰
        sampling_params: LLMé‡‡æ ·å‚æ•°ï¼ˆå¯é€‰ï¼‰
        
    Returns:
        åŒ…å«è¯„ä¼°ç»“æœçš„å­—å…¸
    """
    # ç¬¬ä¸€å±‚ï¼šå¿«é€Ÿåˆ†ç±»ç®€å•é—®é¢˜
    simple_classification = classify_simple_question_type(query)
    
    if simple_classification['is_simple']:
        # ç®€å•é—®é¢˜ï¼šç›´æ¥ä½¿ç”¨åŸºç¡€å¤æ‚åº¦
        base_complexity = simple_classification['base_complexity']
        question_nature_complexity = base_complexity
        
        return {
            'question_type': simple_classification['type'],
            'is_simple': True,
            'base_complexity': base_complexity,
            'question_nature_complexity': question_nature_complexity,
            'description': simple_classification['description'],
            'evaluation_layer': 1,
            'dimension_scores': None
        }
    
    # ç¬¬äºŒå±‚ï¼šå¤æ‚é—®é¢˜ç»†åˆ†ç±»å‹
    complex_classification = classify_complex_question_type(query)
    base_complexity = complex_classification['base_complexity']
    dimension_weights = complex_classification.get('dimension_weights', {
        'rcl': 0.30,
        'kir': 0.25,
        'rrc': 0.20,
        'ds': 0.15,
        'ccd': 0.10
    })
    
    # ç¬¬ä¸‰å±‚ï¼šäº”ç»´åº¦æ·±åº¦è¯„ä¼°
    dim1 = measure_reasoning_chain_length(sub_questions, query)
    dim2 = measure_knowledge_integration_requirement(sub_questions, query)
    dim3 = measure_relational_reasoning_complexity(sub_questions, query)
    dim4 = measure_domain_span(sub_questions, query)
    dim5 = measure_conditional_constraint_density(sub_questions, query)
    
    # ä½¿ç”¨åŠ¨æ€æƒé‡è®¡ç®—äº”ç»´åº¦åŠ æƒåˆ†
    five_dimension_score = (
        dimension_weights['rcl'] * dim1['score'] +
        dimension_weights['kir'] * dim2['score'] +
        dimension_weights['rrc'] * dim3['score'] +
        dimension_weights['ds'] * dim4['score'] +
        dimension_weights['ccd'] * dim5['score']
    )
    
    # æœ€ç»ˆå¤æ‚åº¦ = åŸºç¡€åˆ† Ã— 0.3 + äº”ç»´åº¦åŠ æƒåˆ† Ã— 0.7
    question_nature_complexity = 0.3 * base_complexity + 0.7 * five_dimension_score
    
    return {
        'question_type': complex_classification['type'],
        'is_simple': False,
        'base_complexity': base_complexity,
        'five_dimension_score': five_dimension_score,
        'question_nature_complexity': question_nature_complexity,
        'description': complex_classification['description'],
        'evaluation_layer': 3,
        'dimension_weights': dimension_weights,
        'dimension_scores': {
            'reasoning_chain_length': dim1,
            'knowledge_integration': dim2,
            'relational_reasoning': dim3,
            'domain_span': dim4,
            'conditional_constraint': dim5
        }
    }


def calculate_retrieval_inconsistency(
    bm25_top1_score: float,
    overlap_ratio: float,
    top3_overlap: float
) -> Dict:
    """
    è®¡ç®—æ£€ç´¢ä¸ä¸€è‡´æ€§ï¼ˆåè½¬é€»è¾‘ï¼‰
    
    æ£€ç´¢ä¸ä¸€è‡´æ€§å•åº¦ï¼šè¯„ä¼°æ£€ç´¢ç³»ç»Ÿçš„èƒ½åŠ›
    - åˆ†æ•°è¶Šé«˜ï¼Œè¯´æ˜æ£€ç´¢ç»“æœè¶Šä¸€è‡´ï¼Œé—®é¢˜è¶Šç®€å•
    
    Args:
        bm25_top1_score: BM25 Top1åˆ†æ•°
        overlap_ratio: æ–‡æ¡£é‡å ç‡
        top3_overlap: Top3é‡å ç‡
        
    Returns:
        åŒ…å«è¯„ä¼°ç»“æœçš„å­—å…¸
    """
    # æŸ¥è¯¢ç®€å•æ€§æŒ‡æ•° (QSI) - åŸºäºBM25
    query_simplicity_index = 1.0 / (1.0 + np.exp(0.5 * (bm25_top1_score - 12.5)))
    
    # æ£€ç´¢å·®å¼‚æ€§æŒ‡æ•° (RDI) - åŸºäºé‡å ç‡
    retrieval_divergence = 1.0 - (0.7 * overlap_ratio + 0.3 * top3_overlap)
    
    # ç®€å•é—®é¢˜ç½®ä¿¡åº¦ (ä½¿ç”¨ç«äº‰å‡½æ•°)
    alpha = 1.5
    beta = 0.3
    epsilon = 1e-10
    
    simple_evidence = (query_simplicity_index ** alpha) * (retrieval_divergence ** beta) + epsilon
    complex_evidence = ((1 - query_simplicity_index) ** alpha) * ((1 - retrieval_divergence) ** beta) + epsilon
    
    retrieval_consistency_simplicity = simple_evidence / (simple_evidence + complex_evidence)
    
    # åå¤„ç†ï¼šBM25è¾ƒé«˜ä¸”overlapè¾ƒä½æ—¶çš„æƒ©ç½š
    if bm25_top1_score > 10.0 and overlap_ratio < 0.3:
        bm25_penalty = min(0.95, (bm25_top1_score - 10.0) / 6.0)
        overlap_bonus = overlap_ratio / 0.3
        final_penalty = bm25_penalty * (1.0 - overlap_bonus)
        retrieval_consistency_simplicity = retrieval_consistency_simplicity * (1.0 - final_penalty)
    
    retrieval_consistency_simplicity = np.clip(retrieval_consistency_simplicity, 0, 1)
    
    return {
        'retrieval_consistency_simplicity': retrieval_consistency_simplicity,
        'query_simplicity_index': query_simplicity_index,
        'retrieval_divergence': retrieval_divergence,
        'description': f'æ£€ç´¢ä¸€è‡´æ€§ç®€å•åº¦: {retrieval_consistency_simplicity:.3f}'
    }


def calculate_final_simplicity_score(
    query: str,
    sub_questions: List[str],
    bm25_top1_score: float,
    overlap_ratio: float,
    top3_overlap: float,
    w1: float = 0.5,
    w2: float = 0.5,
    threshold: float = 0.6,
    llm=None,
    sampling_params=None
) -> Dict:
    """
    è®¡ç®—æœ€ç»ˆç®€å•åº¦è¯„åˆ†ï¼ˆä¸»å‡½æ•°ï¼‰
    
    ç»Ÿä¸€ç®€å•åº¦è¯„åˆ†ä½“ç³»ï¼š
    1. é—®é¢˜æœ¬è´¨ç®€å•åº¦ = 1.0 - é—®é¢˜æœ¬è´¨å¤æ‚åº¦
    2. æ£€ç´¢ä¸€è‡´æ€§ç®€å•åº¦ = ç°æœ‰RCCè®¡ç®—
    3. æœ€ç»ˆç®€å•åº¦ = w1 Ã— é—®é¢˜æœ¬è´¨ç®€å•åº¦ + w2 Ã— æ£€ç´¢ä¸€è‡´æ€§ç®€å•åº¦
    4. å†³ç­–è§„åˆ™ï¼šæœ€ç»ˆç®€å•åº¦ â‰¥ threshold â†’ ä¼ ç»ŸRAGï¼›< threshold â†’ KG
    
    Args:
        query: åŸå§‹æŸ¥è¯¢
        sub_questions: å­é—®é¢˜åˆ—è¡¨
        bm25_top1_score: BM25 Top1åˆ†æ•°
        overlap_ratio: æ–‡æ¡£é‡å ç‡
        top3_overlap: Top3é‡å ç‡
        w1: é—®é¢˜æœ¬è´¨æƒé‡ï¼ˆé»˜è®¤0.5ï¼‰
        w2: æ£€ç´¢ä¸€è‡´æ€§æƒé‡ï¼ˆé»˜è®¤0.5ï¼‰
        threshold: å†³ç­–é˜ˆå€¼ï¼ˆé»˜è®¤0.6ï¼‰
        llm: LLMæ¨¡å‹å®ä¾‹ï¼ˆå¯é€‰ï¼‰
        sampling_params: LLMé‡‡æ ·å‚æ•°ï¼ˆå¯é€‰ï¼‰
        
    Returns:
        åŒ…å«æ‰€æœ‰è¯„ä¼°ç»“æœçš„å­—å…¸
    """
    # è®¡ç®—é—®é¢˜æœ¬è´¨ç®€å•åº¦
    question_nature_result = calculate_question_nature_simplicity(
        query, sub_questions, llm, sampling_params
    )
    question_nature_simplicity = question_nature_result['question_nature_simplicity']
    
    # è®¡ç®—æ£€ç´¢ä¸€è‡´æ€§ç®€å•åº¦
    retrieval_result = calculate_retrieval_consistency_simplicity(
        bm25_top1_score, overlap_ratio, top3_overlap
    )
    retrieval_consistency_simplicity = retrieval_result['retrieval_consistency_simplicity']
    
    # è®¡ç®—æœ€ç»ˆç®€å•åº¦
    final_simplicity = w1 * question_nature_simplicity + w2 * retrieval_consistency_simplicity
    final_simplicity = np.clip(final_simplicity, 0, 1)
    
    # å†³ç­–è§„åˆ™
    use_traditional_rag = final_simplicity >= threshold
    
    if use_traditional_rag:
        decision = "ä½¿ç”¨ä¼ ç»ŸRAG"
        reason = f"æœ€ç»ˆç®€å•åº¦{final_simplicity:.3f}â‰¥{threshold}ï¼ˆé—®é¢˜æœ¬è´¨{question_nature_simplicity:.3f} + æ£€ç´¢ä¸€è‡´æ€§{retrieval_consistency_simplicity:.3f}ï¼‰"
    else:
        decision = "ä½¿ç”¨çŸ¥è¯†å›¾è°±"
        reason = f"æœ€ç»ˆç®€å•åº¦{final_simplicity:.3f}<{threshold}ï¼ˆé—®é¢˜æœ¬è´¨{question_nature_simplicity:.3f} + æ£€ç´¢ä¸€è‡´æ€§{retrieval_consistency_simplicity:.3f}ï¼‰"
    
    return {
        # é—®é¢˜ç±»å‹
        'question_type': question_nature_result['question_type'],
        'is_simple_question': question_nature_result['is_simple'],
        'evaluation_layer': question_nature_result['evaluation_layer'],
        
        # é—®é¢˜æœ¬è´¨è¯„ä¼°
        'question_nature_simplicity': round(question_nature_simplicity, 3),
        'question_nature_complexity': round(question_nature_result['question_nature_complexity'], 3),
        'base_complexity': question_nature_result.get('base_complexity'),
        'five_dimension_score': question_nature_result.get('five_dimension_score'),
        'dimension_weights': question_nature_result.get('dimension_weights'),
        'dimension_scores': question_nature_result.get('dimension_scores'),
        
        # æ£€ç´¢ä¸€è‡´æ€§è¯„ä¼°
        'retrieval_consistency_simplicity': round(retrieval_consistency_simplicity, 3),
        'query_simplicity_index': round(retrieval_result['query_simplicity_index'], 3),
        'retrieval_divergence': round(retrieval_result['retrieval_divergence'], 3),
        
        # æœ€ç»ˆè¯„åˆ†
        'final_simplicity': round(final_simplicity, 3),
        'weights': {'w1': w1, 'w2': w2},
        'threshold': threshold,
        
        # å†³ç­–ç»“æœ
        'use_traditional_rag': use_traditional_rag,
        'needs_kg': not use_traditional_rag,
        'decision': decision,
        'reason': reason,
    }


# ==================== å…¼å®¹æ—§æ¥å£ ====================

def measure_multi_hop_requirement(query: str) -> dict:
    """
    è¯„ä¼°æŸ¥è¯¢çš„å¤šè·³æ¨ç†éœ€æ±‚
    
    å•è·³æŸ¥è¯¢ç‰¹å¾ï¼š
    - ç›´æ¥å®šä½åˆ°å…·ä½“æ³•æ¡/æ¦‚å¿µ
    - ç­”æ¡ˆåœ¨å•ä¸€æ–‡æ¡£ä¸­
    - ä¸éœ€è¦è·¨æ–‡æ¡£æ¨ç†
    
    å¤šè·³æŸ¥è¯¢ç‰¹å¾ï¼š
    - éœ€è¦ä»åœºæ™¯æå–è¦ç´ 
    - éœ€è¦åŒ¹é…å¤šä¸ªæ³•å¾‹æ¡ä»¶
    - éœ€è¦ç»¼åˆå¤šä¸ªæ³•æ¡æ¨ç†
    - éœ€è¦å› æœå…³ç³»æ¨ç†
    
    Args:
        query: æŸ¥è¯¢æ–‡æœ¬
        
    Returns:
        åŒ…å«å¤šè·³è¯„ä¼°ç»“æœçš„å­—å…¸
    """
    hop_score = 0.0  # 0=å•è·³, 1=å¤šè·³
    indicators = []
    
    # ========== å•è·³æŒ‡æ ‡ï¼ˆå‡åˆ†ï¼‰==========
    
    # æŒ‡æ ‡1: ç²¾ç¡®æ³•æ¡å®šä½ (-0.5)
    law_article_patterns = [
        r'ç¬¬\d+æ¡',  # ç¬¬85æ¡
        r'ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾]+æ¡',  # ç¬¬å…«åäº”æ¡
        r'\d+æ¡(?!ä»¶)',  # 85æ¡ï¼ˆæ’é™¤"æ¡ä»¶"ï¼‰
        r'ç¬¬\d+æ¬¾',  # ç¬¬2æ¬¾
    ]
    has_article = any(re.search(p, query) for p in law_article_patterns)
    content_words = ['å†…å®¹', 'æ˜¯ä»€ä¹ˆ', 'è¯´çš„æ˜¯', 'è®²äº†ä»€ä¹ˆ', 'è§„å®š', 'å‘Šè¯‰æˆ‘']
    has_content_query = any(word in query for word in content_words)
    
    if has_article and has_content_query and 'åœºæ™¯' not in query:
        hop_score -= 0.5
        indicators.append("ç²¾ç¡®æ³•æ¡å®šä½ï¼ˆå•è·³ï¼‰")
    
    # æŒ‡æ ‡2: ç®€å•æ¦‚å¿µæŸ¥è¯¢ (-0.4)
    concept_patterns = ['ä»€ä¹ˆæ˜¯', 'çš„å®šä¹‰', 'å®šä¹‰æ˜¯', 'æ¦‚å¿µæ˜¯', 'å«ä¹‰æ˜¯']
    if any(p in query for p in concept_patterns):
        hop_score -= 0.4
        indicators.append("æ¦‚å¿µå®šä¹‰æŸ¥è¯¢ï¼ˆå•è·³ï¼‰")
    
    # æŒ‡æ ‡3: ç®€å•åˆ—ä¸¾æŸ¥è¯¢ (-0.3)
    enumeration_patterns = ['åŒ…æ‹¬å“ªäº›', 'åˆ†ä¸ºå“ªå‡ ç§', 'æœ‰å“ªäº›', 'æœ‰å‡ ç§']
    # æ’é™¤éœ€è¦æ¨ç†çš„åˆ—ä¸¾ï¼Œå¦‚"å“ªäº›æƒ…å†µç®—å·¥ä¼¤"
    reasoning_words = ['ç®—', 'å±äº', 'è®¤å®šä¸º', 'åˆ¤æ–­']
    is_simple_enum = any(p in query for p in enumeration_patterns)
    needs_reasoning = any(w in query for w in reasoning_words)
    
    if is_simple_enum and not needs_reasoning:
        hop_score -= 0.3
        indicators.append("ç®€å•åˆ—ä¸¾æŸ¥è¯¢ï¼ˆå•è·³ï¼‰")
    
    # æŒ‡æ ‡4: ç«‹æ³•ç›®çš„/é€‚ç”¨èŒƒå›´æŸ¥è¯¢ (-0.3)
    meta_patterns = ['ç«‹æ³•ç›®çš„', 'ç«‹æ³•å®—æ—¨', 'é€‚ç”¨èŒƒå›´', 'é€‚ç”¨äºå“ªäº›']
    if any(p in query for p in meta_patterns):
        hop_score -= 0.3
        indicators.append("å…ƒä¿¡æ¯æŸ¥è¯¢ï¼ˆå•è·³ï¼‰")
    
    # ========== å¤šè·³æŒ‡æ ‡ï¼ˆåŠ åˆ†ï¼‰==========
    
    # æŒ‡æ ‡1: å…·ä½“åœºæ™¯æè¿° (+0.5) - éœ€è¦åœºæ™¯â†’è¦ç´ â†’æ³•æ¡â†’åˆ¤æ–­
    scenario_keywords = [
        'åœºæ™¯:', 'å…¬å¸', 'è€æ¿', 'å·¥å‚', 'è½¦é—´', 'å•ä½',
        'æˆ‘æ˜¯', 'æˆ‘å¦ˆ', 'æˆ‘çˆ¸', 'æœ¬äºº', 'ä¸‹ç­', 'è·¯ä¸Š', 'é€”ä¸­',
        'å­¦ç”Ÿ', 'è€å¸ˆ', 'ç…¤çŸ¿', 'å…¬å›­', 'èŒå·¥', 'å‘˜å·¥'
    ]
    # æ’é™¤æŠ½è±¡æŸ¥è¯¢ä¸­çš„"å•ä½"ã€"èŒå·¥"ç­‰
    abstract_patterns = ['é€‚ç”¨äº', 'é€‚ç”¨èŒƒå›´', 'ç«‹æ³•ç›®çš„', 'åŒ…æ‹¬å“ªäº›']
    is_abstract = any(p in query for p in abstract_patterns)
    
    has_scenario = any(kw in query for kw in scenario_keywords)
    if has_scenario and not is_abstract:
        hop_score += 0.5
        indicators.append("å…·ä½“åœºæ™¯ï¼ˆå¤šè·³ï¼šåœºæ™¯â†’è¦ç´ â†’æ³•æ¡â†’åˆ¤æ–­ï¼‰")
    
    # æŒ‡æ ‡2: æ¡ä»¶åˆ¤æ–­éœ€æ±‚ (+0.4) - éœ€è¦æ¡ä»¶â†’æ³•æ¡â†’åŒ¹é…â†’ç»“è®º
    judgment_keywords = [
        'ç®—ä¸ç®—', 'æ˜¯å¦', 'èƒ½å¦', 'å¯ä»¥å—', 'åˆç†', 'åˆæ³•',
        'è¿æ³•', 'è¿èƒŒ', 'èƒ½èµ·è¯‰', 'èƒ½æŠ¥', 'è®¤å®šä¸º'
    ]
    # æ’é™¤ç¤¼è²Œç”¨è¯­
    polite_phrases = ['èƒ½å‘Šè¯‰', 'å¯ä»¥å‘Šè¯‰', 'è¯·å‘Šè¯‰']
    is_polite = any(phrase in query for phrase in polite_phrases)
    
    has_judgment = any(kw in query for kw in judgment_keywords)
    if has_judgment and not is_polite:
        hop_score += 0.4
        indicators.append("æ¡ä»¶åˆ¤æ–­ï¼ˆå¤šè·³ï¼šæ¡ä»¶â†’æ³•æ¡â†’åŒ¹é…â†’ç»“è®ºï¼‰")
    
    # æŒ‡æ ‡3: æƒç›Šç»´æŠ¤/æ•‘æµé€”å¾„ (+0.4) - éœ€è¦è¿æ³•è¡Œä¸ºâ†’è´£ä»»â†’æ•‘æµé€”å¾„
    rights_keywords = ['æ‹–æ¬ ', 'è¾é€€', 'è¡¥å¿', 'èµ”å¿', 'æ¬ è–ª', 'ä¸å‘', 'ç»´æƒ']
    remedy_keywords = ['æ€ä¹ˆåŠ', 'åŠæ³•', 'é€”å¾„', 'èµ·è¯‰', 'ä»²è£', 'æŠ•è¯‰']
    
    has_rights_issue = any(kw in query for kw in rights_keywords)
    has_remedy_query = any(kw in query for kw in remedy_keywords)
    
    if has_rights_issue or has_remedy_query:
        hop_score += 0.4
        indicators.append("æƒç›Šç»´æŠ¤ï¼ˆå¤šè·³ï¼šè¿æ³•è¡Œä¸ºâ†’è´£ä»»â†’æ•‘æµï¼‰")
    
    # æŒ‡æ ‡4: å¤šä¸ªæ¡ä»¶ç»„åˆ (+0.3) - éœ€è¦æ¡ä»¶1â†’æ¡ä»¶2â†’ç»¼åˆåˆ¤æ–­
    numeric_conditions = len(re.findall(r'\d+å¹´|\d+å²|\d+ä¸ªæœˆ|\d+æ—¥|\d+å…ƒ', query))
    if numeric_conditions >= 2:
        hop_score += 0.3
        indicators.append(f"å¤šæ¡ä»¶ç»„åˆï¼ˆå¤šè·³ï¼š{numeric_conditions}ä¸ªæ¡ä»¶éœ€ç»¼åˆåˆ¤æ–­ï¼‰")
    
    # æŒ‡æ ‡5: å› æœå…³ç³»æ¨ç† (+0.3) - éœ€è¦åŸå› â†’æ³•æ¡â†’åæœ
    causal_keywords = ['å› ä¸º', 'ç”±äº', 'å¯¼è‡´', 'é€ æˆ', 'å¼•èµ·', 'æ‰€ä»¥', 'ç»“æœ']
    if any(kw in query for kw in causal_keywords):
        hop_score += 0.3
        indicators.append("å› æœæ¨ç†ï¼ˆå¤šè·³ï¼šåŸå› â†’æ³•æ¡â†’åæœï¼‰")
    
    # æŒ‡æ ‡6: å¤æ‚åˆ—ä¸¾ï¼ˆéœ€è¦æ¨ç†çš„åˆ—ä¸¾ï¼‰(+0.3)
    if is_simple_enum and needs_reasoning:
        hop_score += 0.3
        indicators.append("å¤æ‚åˆ—ä¸¾ï¼ˆå¤šè·³ï¼šéœ€è¦æ¨ç†åˆ¤æ–­çš„åˆ—ä¸¾ï¼‰")
    
    # å½’ä¸€åŒ–åˆ°[0, 1]
    hop_score = max(0.0, min(1.0, hop_score))
    
    return {
        'hop_score': hop_score,
        'is_multi_hop': hop_score > 0.0,
        'indicators': indicators
    }


def measure_hierarchical_dependency(query: str) -> dict:
    """
    è¯„ä¼°æŸ¥è¯¢å¯¹å±‚çº§ç»“æ„çš„ä¾èµ–ç¨‹åº¦
    
    å¹³é“ºä¿¡æ¯å³å¯å›ç­”ï¼š
    - å•ä¸€æ³•æ¡å†…å®¹
    - ç‹¬ç«‹çš„æ¦‚å¿µå®šä¹‰
    - ç®€å•çš„åˆ—è¡¨ä¿¡æ¯
    
    éœ€è¦å±‚çº§ç»“æ„è¾…åŠ©ï¼š
    - éœ€è¦ç†è§£æ³•æ¡ä¹‹é—´çš„ä»å±å…³ç³»ï¼ˆæ€»åˆ™â†’åˆ†åˆ™ï¼‰
    - éœ€è¦ç†è§£æ¦‚å¿µä¹‹é—´çš„åŒ…å«å…³ç³»ï¼ˆå·¥ä¼¤â†’å·¥ä¼¤ä¿é™©â†’ç¤¾ä¼šä¿é™©ï¼‰
    - éœ€è¦ç†è§£æ¡ä»¶ä¹‹é—´çš„é€»è¾‘å…³ç³»ï¼ˆå¿…è¦æ¡ä»¶â†’å……åˆ†æ¡ä»¶ï¼‰
    - éœ€è¦ç†è§£ç¨‹åºä¹‹é—´çš„å…ˆåå…³ç³»ï¼ˆåå•†â†’ä»²è£â†’è¯‰è®¼ï¼‰
    
    Args:
        query: æŸ¥è¯¢æ–‡æœ¬
        
    Returns:
        åŒ…å«å±‚çº§ä¾èµ–è¯„ä¼°ç»“æœçš„å­—å…¸
    """
    hierarchy_score = 0.0  # 0=å¹³é“º, 1=å±‚çº§
    indicators = []
    
    # ========== å¹³é“ºä¿¡æ¯æŒ‡æ ‡ï¼ˆå‡åˆ†ï¼‰==========
    
    # æŒ‡æ ‡1: å•ä¸€æ³•æ¡æŸ¥è¯¢ (-0.5)
    law_article_patterns = [
        r'ç¬¬\d+æ¡',
        r'ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾]+æ¡',
        r'\d+æ¡(?!ä»¶)',
        r'ç¬¬\d+æ¬¾',
    ]
    has_article = any(re.search(p, query) for p in law_article_patterns)
    content_words = ['å†…å®¹', 'æ˜¯ä»€ä¹ˆ', 'è¯´çš„æ˜¯', 'è®²äº†ä»€ä¹ˆ', 'è§„å®š']
    has_content_query = any(word in query for word in content_words)
    
    if has_article and has_content_query:
        hierarchy_score -= 0.5
        indicators.append("å•ä¸€æ³•æ¡ï¼ˆå¹³é“ºä¿¡æ¯ï¼‰")
    
    # æŒ‡æ ‡2: ç‹¬ç«‹æ¦‚å¿µå®šä¹‰ (-0.4)
    concept_patterns = ['ä»€ä¹ˆæ˜¯', 'çš„å®šä¹‰', 'å®šä¹‰æ˜¯', 'æ¦‚å¿µæ˜¯', 'å«ä¹‰æ˜¯']
    if any(p in query for p in concept_patterns):
        hierarchy_score -= 0.4
        indicators.append("ç‹¬ç«‹æ¦‚å¿µï¼ˆå¹³é“ºä¿¡æ¯ï¼‰")
    
    # æŒ‡æ ‡3: ç®€å•åˆ—ä¸¾ï¼ˆæ— å±‚çº§å…³ç³»ï¼‰(-0.3)
    simple_enum_patterns = ['åŒ…æ‹¬å“ªäº›', 'æœ‰å“ªäº›', 'æœ‰å‡ ç§']
    if any(p in query for p in simple_enum_patterns):
        hierarchy_score -= 0.3
        indicators.append("ç®€å•åˆ—ä¸¾ï¼ˆå¹³é“ºä¿¡æ¯ï¼‰")
    
    # ========== å±‚çº§ç»“æ„æŒ‡æ ‡ï¼ˆåŠ åˆ†ï¼‰==========
    
    # æŒ‡æ ‡1: ä»å±å…³ç³»æŸ¥è¯¢ (+0.5)
    # ä¾‹å¦‚ï¼š"å·¥ä¼¤ä¿é™©å±äºç¤¾ä¼šä¿é™©å—ï¼Ÿ"
    subordinate_keywords = ['å±äº', 'åŒ…å«åœ¨', 'å½’å±']
    if any(kw in query for kw in subordinate_keywords):
        hierarchy_score += 0.5
        indicators.append("ä»å±å…³ç³»ï¼ˆéœ€è¦å±‚çº§ï¼šå­æ¦‚å¿µâ†’çˆ¶æ¦‚å¿µï¼‰")
    
    # æŒ‡æ ‡2: æ¡ä»¶åˆ¤æ–­æŸ¥è¯¢ (+0.5)
    # ä¾‹å¦‚ï¼š"è¿™ç®—å·¥ä¼¤å—ï¼Ÿ"ã€"èƒ½é€€ä¼‘å—ï¼Ÿ"
    # è¿™ç±»é—®é¢˜éœ€è¦ç†è§£æ¡ä»¶å±‚çº§ï¼šå¿…è¦æ¡ä»¶â†’å……åˆ†æ¡ä»¶â†’ç»¼åˆåˆ¤æ–­
    judgment_keywords = ['ç®—ä¸ç®—', 'æ˜¯ä¸æ˜¯', 'ç®—', 'èƒ½å¦', 'å¯ä»¥å—', 'èƒ½ä¸èƒ½']
    # æ’é™¤ç¤¼è²Œç”¨è¯­
    polite_phrases = ['èƒ½å‘Šè¯‰', 'å¯ä»¥å‘Šè¯‰', 'è¯·å‘Šè¯‰', 'èƒ½ä¸èƒ½å‘Šè¯‰']
    is_polite = any(phrase in query for phrase in polite_phrases)
    
    has_judgment = any(kw in query for kw in judgment_keywords)
    if has_judgment and not is_polite:
        hierarchy_score += 0.5
        indicators.append("æ¡ä»¶åˆ¤æ–­ï¼ˆéœ€è¦å±‚çº§ï¼šæ¡ä»¶Aâˆ§æ¡ä»¶Bâ†’ç»“è®ºï¼‰")
    
    # æŒ‡æ ‡3: æ¡ä»¶å±‚çº§æŸ¥è¯¢ (+0.4)
    # ä¾‹å¦‚ï¼š"æ»¡è¶³å“ªäº›æ¡ä»¶æ‰èƒ½è®¤å®šä¸ºå·¥ä¼¤ï¼Ÿ"
    condition_keywords = ['æ»¡è¶³', 'ç¬¦åˆ', 'æ¡ä»¶', 'è¦æ±‚', 'å‰æ', 'å¿…é¡»']
    recognition_keywords = ['è®¤å®š', 'åˆ¤æ–­', 'ç¡®å®š', 'ç®—ä½œ']
    
    has_condition = any(kw in query for kw in condition_keywords)
    has_recognition = any(kw in query for kw in recognition_keywords)
    
    if has_condition or has_recognition:
        hierarchy_score += 0.4
        indicators.append("æ¡ä»¶å±‚çº§ï¼ˆéœ€è¦å±‚çº§ï¼šå¿…è¦æ¡ä»¶â†’å……åˆ†æ¡ä»¶ï¼‰")
    
    # æŒ‡æ ‡3: ç¨‹åº/æµç¨‹æŸ¥è¯¢ (+0.4)
    # ä¾‹å¦‚ï¼š"åŠ³åŠ¨äº‰è®®çš„å¤„ç†æµç¨‹æ˜¯ä»€ä¹ˆï¼Ÿ"
    procedure_keywords = ['æµç¨‹', 'ç¨‹åº', 'æ­¥éª¤', 'è¿‡ç¨‹', 'æ€ä¹ˆåŠ', 'å¦‚ä½•å¤„ç†']
    if any(kw in query for kw in procedure_keywords):
        hierarchy_score += 0.4
        indicators.append("ç¨‹åºå±‚çº§ï¼ˆéœ€è¦å±‚çº§ï¼šæ­¥éª¤1â†’æ­¥éª¤2â†’æ­¥éª¤3ï¼‰")
    
    # æŒ‡æ ‡4: å…³ç³»æ¨ç†æŸ¥è¯¢ (+0.4)
    # ä¾‹å¦‚ï¼š"ç”¨äººå•ä½å’ŒåŠ³åŠ¨è€…çš„å…³ç³»æ˜¯ä»€ä¹ˆï¼Ÿ"
    relation_keywords = ['å…³ç³»', 'åŒºåˆ«', 'è”ç³»', 'å¯¹æ¯”', 'æ¯”è¾ƒ']
    if any(kw in query for kw in relation_keywords):
        hierarchy_score += 0.4
        indicators.append("å…³ç³»æ¨ç†ï¼ˆéœ€è¦å±‚çº§ï¼šå®ä½“Aâ†”å…³ç³»â†”å®ä½“Bï¼‰")
    
    # æŒ‡æ ‡5: èŒƒå›´/è¾¹ç•ŒæŸ¥è¯¢ (+0.3)
    # ä¾‹å¦‚ï¼š"å“ªäº›æƒ…å†µç®—å·¥ä¼¤ï¼Ÿ"ï¼ˆéœ€è¦ç†è§£å·¥ä¼¤çš„è¾¹ç•Œï¼‰
    scope_keywords = ['å“ªäº›æƒ…å†µ', 'ä»€ä¹ˆæƒ…å†µ', 'èŒƒå›´', 'è¾¹ç•Œ', 'ç•Œå®š']
    if any(kw in query for kw in scope_keywords):
        hierarchy_score += 0.3
        indicators.append("èŒƒå›´ç•Œå®šï¼ˆéœ€è¦å±‚çº§ï¼šæ ¸å¿ƒæƒ…å†µâ†’è¾¹ç•Œæƒ…å†µï¼‰")
    
    # æŒ‡æ ‡6: è´£ä»»/åæœæŸ¥è¯¢ (+0.4)
    # ä¾‹å¦‚ï¼š"å…¬å¸è¿æ³•éœ€è¦æ‰¿æ‹…ä»€ä¹ˆè´£ä»»ï¼Ÿ"ï¼ˆéœ€è¦ç†è§£è¿æ³•è¡Œä¸ºâ†’æ³•å¾‹è´£ä»»çš„å±‚çº§ï¼‰
    responsibility_keywords = ['è´£ä»»', 'åæœ', 'å¤„ç½š', 'èµ”å¿', 'è¡¥å¿']
    if any(kw in query for kw in responsibility_keywords):
        hierarchy_score += 0.4
        indicators.append("è´£ä»»åæœï¼ˆéœ€è¦å±‚çº§ï¼šè¿æ³•è¡Œä¸ºâ†’æ³•å¾‹è´£ä»»â†’å…·ä½“åæœï¼‰")
    
    # æŒ‡æ ‡7: å¤šä¸»ä½“å…³ç³» (+0.3)
    # ä¾‹å¦‚ï¼š"ç”¨äººå•ä½ã€åŠ³åŠ¨è€…ã€å·¥ä¼šçš„å…³ç³»"
    # æ£€æµ‹æ˜¯å¦æ¶‰åŠå¤šä¸ªæ³•å¾‹ä¸»ä½“
    subjects = ['ç”¨äººå•ä½', 'åŠ³åŠ¨è€…', 'èŒå·¥', 'å·¥ä¼š', 'æ”¿åºœ', 'éƒ¨é—¨', 'æœºæ„']
    subject_count = sum(1 for s in subjects if s in query)
    if subject_count >= 2:
        hierarchy_score += 0.3
        indicators.append(f"å¤šä¸»ä½“å…³ç³»ï¼ˆéœ€è¦å±‚çº§ï¼š{subject_count}ä¸ªä¸»ä½“çš„å…³ç³»ç½‘ç»œï¼‰")
    
    # å½’ä¸€åŒ–åˆ°[0, 1]
    hierarchy_score = max(0.0, min(1.0, hierarchy_score))
    
    return {
        'hierarchy_score': hierarchy_score,
        'needs_hierarchy': hierarchy_score > 0.0,
        'indicators': indicators
    }


def measure_query_simplicity(query: str) -> float:
    """
    ç»¼åˆè¯„ä¼°æŸ¥è¯¢ç®€å•åº¦ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰
    
    ç®€å•åº¦ = 1 - (å¤šè·³éœ€æ±‚ + å±‚çº§ä¾èµ–) / 2
    
    Args:
        query: æŸ¥è¯¢æ–‡æœ¬
        
    Returns:
        ç®€å•åº¦åˆ†æ•° (0-1)ï¼Œè¶Šé«˜è¶Šç®€å•
    """
    hop_result = measure_multi_hop_requirement(query)
    hierarchy_result = measure_hierarchical_dependency(query)
    
    # å¤æ‚åº¦ = (å¤šè·³åˆ†æ•° + å±‚çº§åˆ†æ•°) / 2
    complexity = (hop_result['hop_score'] + hierarchy_result['hierarchy_score']) / 2
    
    # ç®€å•åº¦ = 1 - å¤æ‚åº¦
    simplicity = 1.0 - complexity
    
    return simplicity


def calculate_combined_score_with_simplicity(
    query: str,
    bm25_top1_score: float,
    overlap_ratio: float,
    top3_overlap: float,
    llm=None,
    sampling_params=None,
    use_five_dimensions: bool = True
) -> dict:
    """
    ç»¼åˆè®¡ç®—é—®é¢˜å¤æ‚åº¦ï¼ˆæ”¯æŒæ–°æ—§ä¸¤ç§æ¨¡å¼ï¼‰
    
    æ–°æ¨¡å¼ï¼ˆuse_five_dimensions=Trueï¼‰ï¼š
    - ä½¿ç”¨ç»Ÿä¸€ç®€å•åº¦è¯„åˆ†ä½“ç³»
    - ä¸‰å±‚è¯„ä¼°æ¶æ„ï¼šé—®é¢˜ç±»å‹åˆ†ç±» â†’ å¤æ‚é—®é¢˜ç»†åˆ† â†’ äº”ç»´åº¦è¯„ä¼°
    - æœ€ç»ˆç®€å•åº¦ = 0.5 Ã— é—®é¢˜æœ¬è´¨ç®€å•åº¦ + 0.5 Ã— æ£€ç´¢ä¸€è‡´æ€§ç®€å•åº¦
    - å†³ç­–è§„åˆ™ï¼šæœ€ç»ˆç®€å•åº¦ â‰¥ 0.6 â†’ ä¼ ç»ŸRAGï¼›< 0.6 â†’ KG
    
    æ—§æ¨¡å¼ï¼ˆuse_five_dimensions=Falseï¼‰ï¼š
    - ä½¿ç”¨åŸæœ‰çš„å¤šè·³æ¨ç†+å±‚çº§ç»“æ„è¯„ä¼°
    - ä¿æŒå‘åå…¼å®¹
    
    Args:
        query: æŸ¥è¯¢æ–‡æœ¬
        bm25_top1_score: BM25 Top1åˆ†æ•°
        overlap_ratio: æ–‡æ¡£é‡å ç‡
        top3_overlap: Top3é‡å ç‡
        llm: LLMæ¨¡å‹å®ä¾‹ï¼ˆå¯é€‰ï¼Œç”¨äºå­é—®é¢˜æ‹†åˆ†ï¼‰
        sampling_params: LLMé‡‡æ ·å‚æ•°ï¼ˆå¯é€‰ï¼‰
        use_five_dimensions: æ˜¯å¦ä½¿ç”¨æ–°çš„ç»Ÿä¸€ç®€å•åº¦è¯„åˆ†ï¼ˆé»˜è®¤Trueï¼‰
        
    Returns:
        åŒ…å«å„é¡¹æŒ‡æ ‡çš„å­—å…¸
    """
    if use_five_dimensions:
        # ========== æ–°æ¨¡å¼ï¼šç»Ÿä¸€ç®€å•åº¦è¯„åˆ†ä½“ç³» ==========
        
        # æ­¥éª¤1: LLMæ‹†åˆ†å­é—®é¢˜
        decomposition = decompose_query_with_llm(query, llm, sampling_params)
        sub_questions = decomposition['sub_questions']
        
        # æ­¥éª¤2: è®¡ç®—æœ€ç»ˆç®€å•åº¦ï¼ˆä¸‰å±‚è¯„ä¼°æ¶æ„ï¼‰
        result = calculate_final_simplicity_score(
            query=query,
            sub_questions=sub_questions,
            bm25_top1_score=bm25_top1_score,
            overlap_ratio=overlap_ratio,
            top3_overlap=top3_overlap,
            w1=0.5,  # é—®é¢˜æœ¬è´¨æƒé‡
            w2=0.5,  # æ£€ç´¢ä¸€è‡´æ€§æƒé‡
            threshold=0.6,  # å†³ç­–é˜ˆå€¼
            llm=llm,
            sampling_params=sampling_params
        )
        
        # æ·»åŠ æ‹†åˆ†ä¿¡æ¯
        result['decomposition'] = decomposition
        result['sub_questions'] = sub_questions
        result['num_sub_questions'] = len(sub_questions)
        result['mode'] = 'unified_simplicity'
        
        return result
    
    else:
        # ========== æ—§æ¨¡å¼ï¼šå¤šè·³+å±‚çº§è¯„ä¼°ï¼ˆä¿æŒå…¼å®¹ï¼‰==========
        
        # ç»´åº¦1: å¤šè·³æ¨ç†éœ€æ±‚
        hop_result = measure_multi_hop_requirement(query)
        multi_hop_score = hop_result['hop_score']
        
        # ç»´åº¦2: å±‚çº§ç»“æ„ä¾èµ–
        hierarchy_result = measure_hierarchical_dependency(query)
        hierarchy_score = hierarchy_result['hierarchy_score']
        
        # ç»´åº¦3: æ£€ç´¢ä¸€è‡´æ€§ç½®ä¿¡åº¦
        rcc = calculate_retrieval_consistency_confidence(
            bm25_top1_score, overlap_ratio, top3_overlap
        )
        retrieval_consistency_confidence = rcc['score']
        
        # ç»¼åˆè¯„åˆ†
        query_structure_complexity = (multi_hop_score + hierarchy_score) / 2
        query_structure_simplicity = 1.0 - query_structure_complexity
        
        weight_structure = 0.5
        weight_retrieval = 0.5
        
        final_simplicity_score = (
            weight_structure * query_structure_simplicity +
            weight_retrieval * retrieval_consistency_confidence
        )
        
        # ä¸€è‡´æ€§æ£€æŸ¥
        dimension_diff = abs(query_structure_simplicity - retrieval_consistency_confidence)
        if dimension_diff > 0.4:
            consistency_penalty = 0.1
            final_simplicity_score = final_simplicity_score * (1.0 - consistency_penalty)
        
        return {
            # ç»´åº¦1: å¤šè·³æ¨ç†éœ€æ±‚
            'multi_hop_score': round(multi_hop_score, 3),
            'is_multi_hop': hop_result['is_multi_hop'],
            'hop_indicators': hop_result['indicators'],
            
            # ç»´åº¦2: å±‚çº§ç»“æ„ä¾èµ–
            'hierarchy_score': round(hierarchy_score, 3),
            'needs_hierarchy': hierarchy_result['needs_hierarchy'],
            'hierarchy_indicators': hierarchy_result['indicators'],
            
            # æŸ¥è¯¢ç»“æ„ç»¼åˆ
            'query_structure_complexity': round(query_structure_complexity, 3),
            'query_structure_simplicity': round(query_structure_simplicity, 3),
            
            # ç»´åº¦3: æ£€ç´¢ä¸€è‡´æ€§
            'query_simplicity_index': round(rcc['query_simplicity_index'], 3),
            'retrieval_divergence': round(rcc['retrieval_divergence'], 3),
            'retrieval_consistency_confidence': round(retrieval_consistency_confidence, 3),
            
            # ç»¼åˆè¯„åˆ†
            'final_simplicity_score': round(final_simplicity_score, 3),
            'dimension_difference': round(dimension_diff, 3),
            
            # åˆ¤æ–­ç»“æœ
            'is_simple': final_simplicity_score >= 0.5,
            'confidence': 'high' if dimension_diff < 0.2 else 'medium' if dimension_diff < 0.4 else 'low',
            
            # å†³ç­–å»ºè®®
            'needs_kg': multi_hop_score > 0.3 or hierarchy_score > 0.3,
            'reason': _generate_decision_reason(multi_hop_score, hierarchy_score, final_simplicity_score),
            'mode': 'legacy'
        }


def calculate_combined_score_with_simplicity_old(
    query: str,
    bm25_top1_score: float,
    overlap_ratio: float,
    top3_overlap: float
) -> dict:
    """
    ç»¼åˆè®¡ç®—é—®é¢˜å¤æ‚åº¦ï¼ˆé‡æ„ç‰ˆï¼‰
    
    ä¸‰ä¸ªç»´åº¦ï¼š
    1. å¤šè·³æ¨ç†éœ€æ±‚ (Multi-hop Reasoning Requirement, MRR)
       - è¯„ä¼°æ˜¯å¦éœ€è¦å¤šæ­¥æ¨ç†
       - èŒƒå›´ï¼š[0, 1]ï¼Œ0=å•è·³ï¼Œ1=å¤šè·³
    
    2. å±‚çº§ç»“æ„ä¾èµ– (Hierarchical Structure Dependency, HSD)
       - è¯„ä¼°æ˜¯å¦éœ€è¦å±‚çº§ç»“æ„è¾…åŠ©ç†è§£
       - èŒƒå›´ï¼š[0, 1]ï¼Œ0=å¹³é“ºï¼Œ1=å±‚çº§
    
    3. æ£€ç´¢ä¸€è‡´æ€§ç½®ä¿¡åº¦ (Retrieval Consistency Confidence, RCC)
       - åŸºäºBM25åˆ†æ•°å’Œé‡å ç‡åˆ¤æ–­æ£€ç´¢éš¾åº¦
       - èŒƒå›´ï¼š[0, 1]ï¼Œè¶Šé«˜è¶Šç®€å•
    
    æœ€ç»ˆç®€å•åº¦ = 1 - (MRR + HSD) / 2 çš„åŠ æƒç»„åˆ
    
    Args:
        query: æŸ¥è¯¢æ–‡æœ¬
        bm25_top1_score: BM25 Top1åˆ†æ•°
        overlap_ratio: æ–‡æ¡£é‡å ç‡
        top3_overlap: Top3é‡å ç‡
        
    Returns:
        åŒ…å«å„é¡¹æŒ‡æ ‡çš„å­—å…¸
    """
    # ========== ç»´åº¦1: å¤šè·³æ¨ç†éœ€æ±‚ (MRR) ==========
    hop_result = measure_multi_hop_requirement(query)
    multi_hop_score = hop_result['hop_score']
    
    # ========== ç»´åº¦2: å±‚çº§ç»“æ„ä¾èµ– (HSD) ==========
    hierarchy_result = measure_hierarchical_dependency(query)
    hierarchy_score = hierarchy_result['hierarchy_score']
    
    # ========== ç»´åº¦3: æ£€ç´¢ä¸€è‡´æ€§ç½®ä¿¡åº¦ (RCC) ==========
    # 3.1 æŸ¥è¯¢ç®€å•æ€§æŒ‡æ•° (QSI) - åŸºäºBM25
    query_simplicity_index = 1.0 / (1.0 + np.exp(0.5 * (bm25_top1_score - 12.5)))
    
    # 3.2 æ£€ç´¢å·®å¼‚æ€§æŒ‡æ•° (RDI) - åŸºäºé‡å ç‡
    retrieval_divergence = 1.0 - (0.7 * overlap_ratio + 0.3 * top3_overlap)
    
    # 3.3 ç®€å•é—®é¢˜ç½®ä¿¡åº¦ (ä½¿ç”¨ç«äº‰å‡½æ•°)
    alpha = 1.5
    beta = 0.3
    epsilon = 1e-10
    
    simple_evidence = (query_simplicity_index ** alpha) * (retrieval_divergence ** beta) + epsilon
    complex_evidence = ((1 - query_simplicity_index) ** alpha) * ((1 - retrieval_divergence) ** beta) + epsilon
    
    retrieval_consistency_confidence = simple_evidence / (simple_evidence + complex_evidence)
    
    # åå¤„ç†ï¼šBM25è¾ƒé«˜ä¸”overlapè¾ƒä½æ—¶çš„æƒ©ç½š
    if bm25_top1_score > 10.0 and overlap_ratio < 0.3:
        bm25_penalty = min(0.95, (bm25_top1_score - 10.0) / 6.0)
        overlap_bonus = overlap_ratio / 0.3
        final_penalty = bm25_penalty * (1.0 - overlap_bonus)
        retrieval_consistency_confidence = retrieval_consistency_confidence * (1.0 - final_penalty)
    
    retrieval_consistency_confidence = np.clip(retrieval_consistency_confidence, 0, 1)
    
    # ========== ç»¼åˆè¯„åˆ† ==========
    # æŸ¥è¯¢ç»“æ„å¤æ‚åº¦ = (å¤šè·³éœ€æ±‚ + å±‚çº§ä¾èµ–) / 2
    query_structure_complexity = (multi_hop_score + hierarchy_score) / 2
    query_structure_simplicity = 1.0 - query_structure_complexity
    
    # æƒé‡åˆ†é…ï¼š
    # - æŸ¥è¯¢ç»“æ„æƒé‡ 50%ï¼ˆé—®é¢˜æœ¬è´¨ï¼šå¤šè·³+å±‚çº§ï¼‰
    # - æ£€ç´¢ä¸€è‡´æ€§æƒé‡ 50%ï¼ˆæ£€ç´¢éš¾åº¦ï¼‰
    weight_structure = 0.5
    weight_retrieval = 0.5
    
    final_simplicity_score = (
        weight_structure * query_structure_simplicity +
        weight_retrieval * retrieval_consistency_confidence
    )
    
    # ========== ä¸€è‡´æ€§æ£€æŸ¥ ==========
    # å¦‚æœæŸ¥è¯¢ç»“æ„å’Œæ£€ç´¢ä¸€è‡´æ€§å·®å¼‚å¾ˆå¤§ï¼Œè¯´æ˜å­˜åœ¨å†²çª
    dimension_diff = abs(query_structure_simplicity - retrieval_consistency_confidence)
    if dimension_diff > 0.4:
        # é™ä½10%çš„ç½®ä¿¡åº¦
        consistency_penalty = 0.1
        final_simplicity_score = final_simplicity_score * (1.0 - consistency_penalty)
    
    return {
        # ç»´åº¦1: å¤šè·³æ¨ç†éœ€æ±‚
        'multi_hop_score': round(multi_hop_score, 3),
        'is_multi_hop': hop_result['is_multi_hop'],
        'hop_indicators': hop_result['indicators'],
        
        # ç»´åº¦2: å±‚çº§ç»“æ„ä¾èµ–
        'hierarchy_score': round(hierarchy_score, 3),
        'needs_hierarchy': hierarchy_result['needs_hierarchy'],
        'hierarchy_indicators': hierarchy_result['indicators'],
        
        # æŸ¥è¯¢ç»“æ„ç»¼åˆ
        'query_structure_complexity': round(query_structure_complexity, 3),
        'query_structure_simplicity': round(query_structure_simplicity, 3),
        
        # ç»´åº¦3: æ£€ç´¢ä¸€è‡´æ€§
        'query_simplicity_index': round(query_simplicity_index, 3),
        'retrieval_divergence': round(retrieval_divergence, 3),
        'retrieval_consistency_confidence': round(retrieval_consistency_confidence, 3),
        
        # ç»¼åˆè¯„åˆ†
        'final_simplicity_score': round(final_simplicity_score, 3),
        'dimension_difference': round(dimension_diff, 3),
        
        # åˆ¤æ–­ç»“æœ
        'is_simple': final_simplicity_score >= 0.5,
        'confidence': 'high' if dimension_diff < 0.2 else 'medium' if dimension_diff < 0.4 else 'low',
        
        # å†³ç­–å»ºè®®
        'needs_kg': multi_hop_score > 0.3 or hierarchy_score > 0.3,
        'reason': _generate_decision_reason(multi_hop_score, hierarchy_score, final_simplicity_score)
    }


def _generate_decision_reason(multi_hop: float, hierarchy: float, simplicity: float) -> str:
    """ç”Ÿæˆå†³ç­–ç†ç”±"""
    if simplicity >= 0.7:
        return "ç®€å•é—®é¢˜ï¼šå•è·³æŸ¥è¯¢ï¼Œå¹³é“ºä¿¡æ¯å³å¯ï¼Œä½¿ç”¨æ··åˆæ£€ç´¢"
    elif simplicity >= 0.5:
        return "ä¸­ç­‰é—®é¢˜ï¼šè½»åº¦æ¨ç†éœ€æ±‚ï¼Œæ··åˆæ£€ç´¢å¯èƒ½è¶³å¤Ÿ"
    elif multi_hop > 0.5 and hierarchy > 0.5:
        return "å¤æ‚é—®é¢˜ï¼šéœ€è¦å¤šè·³æ¨ç†ä¸”ä¾èµ–å±‚çº§ç»“æ„ï¼Œå¼ºçƒˆå»ºè®®ä½¿ç”¨çŸ¥è¯†å›¾è°±"
    elif multi_hop > 0.5:
        return "å¤æ‚é—®é¢˜ï¼šéœ€è¦å¤šè·³æ¨ç†ï¼Œå»ºè®®ä½¿ç”¨çŸ¥è¯†å›¾è°±è¾…åŠ©"
    elif hierarchy > 0.5:
        return "å¤æ‚é—®é¢˜ï¼šéœ€è¦å±‚çº§ç»“æ„ç†è§£ï¼Œå»ºè®®ä½¿ç”¨çŸ¥è¯†å›¾è°±è¾…åŠ©"
    else:
        return "å¤æ‚é—®é¢˜ï¼šæ£€ç´¢ä¸€è‡´æ€§ä½ï¼Œå»ºè®®ä½¿ç”¨çŸ¥è¯†å›¾è°±"


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    print("=" * 100)
    print("æŸ¥è¯¢ç®€å•åº¦è¯„ä¼°æ¨¡å—æµ‹è¯•ï¼ˆé‡æ„ç‰ˆï¼‰")
    print("=" * 100)
    
    # æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        # ç®€å•é—®é¢˜ï¼ˆå•è·³ + å¹³é“ºï¼‰
        {
            'query': 'ã€ŠåŠ³åŠ¨åˆåŒæ³•ã€‹ç¬¬85æ¡çš„å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿ',
            'type': 'ç®€å•é—®é¢˜',
            'expected': 'å•è·³ + å¹³é“º'
        },
        {
            'query': 'ä»€ä¹ˆæ˜¯åŠ³åŠ¨åˆåŒï¼Ÿ',
            'type': 'ç®€å•é—®é¢˜',
            'expected': 'å•è·³ + å¹³é“º'
        },
        {
            'query': 'åŠ³åŠ¨åˆåŒæ³•çš„ç«‹æ³•ç›®çš„æ˜¯ä»€ä¹ˆï¼Ÿ',
            'type': 'ç®€å•é—®é¢˜',
            'expected': 'å•è·³ + å¹³é“º'
        },
        
        # ä¸­ç­‰é—®é¢˜ï¼ˆå•è·³ + å±‚çº§ æˆ– å¤šè·³ + å¹³é“ºï¼‰
        {
            'query': 'å·¥ä¼¤ä¿é™©å±äºç¤¾ä¼šä¿é™©å—ï¼Ÿ',
            'type': 'ä¸­ç­‰é—®é¢˜',
            'expected': 'å•è·³ + å±‚çº§ï¼ˆä»å±å…³ç³»ï¼‰'
        },
        {
            'query': 'å“ªäº›æƒ…å†µç®—å·¥ä¼¤ï¼Ÿ',
            'type': 'ä¸­ç­‰é—®é¢˜',
            'expected': 'å•è·³ + å±‚çº§ï¼ˆèŒƒå›´ç•Œå®šï¼‰'
        },
        
        # å¤æ‚é—®é¢˜ï¼ˆå¤šè·³ + å±‚çº§ï¼‰
        {
            'query': 'æˆ‘åœ¨å·¥å‚ä¸Šç­ï¼Œä¸‹ç­è·¯ä¸Šæ‘”ä¼¤äº†ï¼Œè¿™ç®—å·¥ä¼¤å—ï¼Ÿ',
            'type': 'å¤æ‚é—®é¢˜',
            'expected': 'å¤šè·³ï¼ˆåœºæ™¯æ¨ç†ï¼‰+ å±‚çº§ï¼ˆæ¡ä»¶åˆ¤æ–­ï¼‰'
        },
        {
            'query': 'å…¬å¸æ‹–æ¬ æˆ‘å·¥èµ„ï¼Œæˆ‘è¯¥æ€ä¹ˆåŠï¼Ÿ',
            'type': 'å¤æ‚é—®é¢˜',
            'expected': 'å¤šè·³ï¼ˆæƒç›Šç»´æŠ¤ï¼‰+ å±‚çº§ï¼ˆç¨‹åºæµç¨‹ï¼‰'
        },
        {
            'query': 'æˆ‘æ˜¯75å¹´çš„å¥³èŒå·¥ï¼Œäº¤äº†5å¹´ç¤¾ä¿ï¼Œèƒ½é€€ä¼‘å—ï¼Ÿ',
            'type': 'å¤æ‚é—®é¢˜',
            'expected': 'å¤šè·³ï¼ˆå¤šæ¡ä»¶ï¼‰+ å±‚çº§ï¼ˆæ¡ä»¶åˆ¤æ–­ï¼‰'
        },
        {
            'query': 'æ»¡è¶³å“ªäº›æ¡ä»¶æ‰èƒ½è®¤å®šä¸ºå·¥ä¼¤ï¼Ÿ',
            'type': 'å¤æ‚é—®é¢˜',
            'expected': 'å¤šè·³ï¼ˆå¤æ‚åˆ—ä¸¾ï¼‰+ å±‚çº§ï¼ˆæ¡ä»¶å±‚çº§ï¼‰'
        },
    ]
    
    for i, case in enumerate(test_cases, 1):
        query = case['query']
        print(f"\n{'='*100}")
        print(f"æµ‹è¯• {i}: {case['type']}")
        print(f"{'='*100}")
        print(f"æŸ¥è¯¢: {query}")
        print(f"é¢„æœŸ: {case['expected']}")
        print(f"\n{'-'*100}")
        
        # è¯„ä¼°å¤šè·³æ¨ç†éœ€æ±‚
        hop_result = measure_multi_hop_requirement(query)
        print(f"\nã€ç»´åº¦1: å¤šè·³æ¨ç†éœ€æ±‚ã€‘")
        print(f"  åˆ†æ•°: {hop_result['hop_score']:.3f} ({'å¤šè·³' if hop_result['is_multi_hop'] else 'å•è·³'})")
        if hop_result['indicators']:
            print(f"  æŒ‡æ ‡:")
            for indicator in hop_result['indicators']:
                print(f"    - {indicator}")
        
        # è¯„ä¼°å±‚çº§ç»“æ„ä¾èµ–
        hierarchy_result = measure_hierarchical_dependency(query)
        print(f"\nã€ç»´åº¦2: å±‚çº§ç»“æ„ä¾èµ–ã€‘")
        print(f"  åˆ†æ•°: {hierarchy_result['hierarchy_score']:.3f} ({'éœ€è¦å±‚çº§' if hierarchy_result['needs_hierarchy'] else 'å¹³é“ºä¿¡æ¯'})")
        if hierarchy_result['indicators']:
            print(f"  æŒ‡æ ‡:")
            for indicator in hierarchy_result['indicators']:
                print(f"    - {indicator}")
        
        # ç»¼åˆç®€å•åº¦
        simplicity = measure_query_simplicity(query)
        print(f"\nã€ç»¼åˆç®€å•åº¦ã€‘")
        print(f"  åˆ†æ•°: {simplicity:.3f} ({'ç®€å•' if simplicity >= 0.5 else 'å¤æ‚'})")
        
        # æ¨¡æ‹Ÿæ£€ç´¢æŒ‡æ ‡è¿›è¡Œå®Œæ•´è¯„ä¼°
        if case['type'] == 'ç®€å•é—®é¢˜':
            bm25, overlap, top3 = 8.0, 0.8, 1.0
        elif case['type'] == 'ä¸­ç­‰é—®é¢˜':
            bm25, overlap, top3 = 12.0, 0.5, 0.67
        else:
            bm25, overlap, top3 = 15.0, 0.2, 0.0
        
        result = calculate_combined_score_with_simplicity(
            query=query,
            bm25_top1_score=bm25,
            overlap_ratio=overlap,
            top3_overlap=top3,
            use_five_dimensions=False  # ä½¿ç”¨æ—§æ¨¡å¼
        )
        
        print(f"\nã€å®Œæ•´è¯„ä¼°ï¼ˆå«æ£€ç´¢æŒ‡æ ‡ï¼‰ã€‘")
        print(f"  å¤šè·³æ¨ç†: {result['multi_hop_score']:.3f}")
        print(f"  å±‚çº§ä¾èµ–: {result['hierarchy_score']:.3f}")
        print(f"  æŸ¥è¯¢ç»“æ„å¤æ‚åº¦: {result['query_structure_complexity']:.3f}")
        print(f"  æ£€ç´¢ä¸€è‡´æ€§ç½®ä¿¡åº¦: {result['retrieval_consistency_confidence']:.3f}")
        print(f"  æœ€ç»ˆç®€å•åº¦: {result['final_simplicity_score']:.3f}")
        print(f"  åˆ¤æ–­: {'ç®€å•' if result['is_simple'] else 'å¤æ‚'} (ç½®ä¿¡åº¦: {result['confidence']})")
        print(f"  æ˜¯å¦éœ€è¦KG: {'æ˜¯' if result['needs_kg'] else 'å¦'}")
        print(f"  å†³ç­–ç†ç”±: {result['reason']}")
    
    print(f"\n{'='*100}")
    print("æµ‹è¯•å®Œæˆ")
    print("="*100)


# ==================== æ–°å¢æµ‹è¯•ä»£ç  ====================

def test_five_dimensions():
    """æµ‹è¯•5ç»´åº¦è¯„ä¼°ï¼ˆä¸ä½¿ç”¨LLMï¼‰"""
    print("=" * 100)
    print("æŸ¥è¯¢ç®€å•åº¦è¯„ä¼°æ¨¡å—æµ‹è¯•ï¼ˆ5ç»´åº¦ç‰ˆæœ¬ï¼‰")
    print("=" * 100)
    
    # æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        # ç®€å•é—®é¢˜
        {
            'query': 'ã€ŠåŠ³åŠ¨åˆåŒæ³•ã€‹ç¬¬85æ¡çš„å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿ',
            'type': 'ç®€å•é—®é¢˜',
            'sub_questions': ['ã€ŠåŠ³åŠ¨åˆåŒæ³•ã€‹ç¬¬85æ¡çš„å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿ'],
            'bm25': 8.0, 'overlap': 0.8, 'top3': 1.0
        },
        {
            'query': 'ä»€ä¹ˆæ˜¯åŠ³åŠ¨åˆåŒï¼Ÿ',
            'type': 'ç®€å•é—®é¢˜',
            'sub_questions': ['ä»€ä¹ˆæ˜¯åŠ³åŠ¨åˆåŒï¼Ÿ'],
            'bm25': 8.0, 'overlap': 0.8, 'top3': 1.0
        },
        
        # ä¸­ç­‰é—®é¢˜
        {
            'query': 'å·¥ä¼¤ä¿é™©å±äºç¤¾ä¼šä¿é™©å—ï¼Ÿ',
            'type': 'ä¸­ç­‰é—®é¢˜',
            'sub_questions': ['å·¥ä¼¤ä¿é™©å±äºç¤¾ä¼šä¿é™©å—ï¼Ÿ', 'å·¥ä¼¤ä¿é™©çš„å®šä¹‰æ˜¯ä»€ä¹ˆï¼Ÿ'],
            'bm25': 12.0, 'overlap': 0.5, 'top3': 0.67
        },
        
        # å¤æ‚é—®é¢˜
        {
            'query': 'æˆ‘åœ¨å·¥å‚ä¸Šç­ï¼Œä¸‹ç­è·¯ä¸Šæ‘”ä¼¤äº†ï¼Œè¿™ç®—å·¥ä¼¤å—ï¼Ÿ',
            'type': 'å¤æ‚é—®é¢˜',
            'sub_questions': [
                "ä»€ä¹ˆæƒ…å†µç®—å·¥ä¼¤ï¼Ÿ",
                "ä¸‹ç­è·¯ä¸Šå—ä¼¤ç®—å·¥ä¼¤å—ï¼Ÿ",
                "å·¥ä¼¤è®¤å®šçš„æ¡ä»¶æ˜¯ä»€ä¹ˆï¼Ÿ"
            ],
            'bm25': 15.0, 'overlap': 0.2, 'top3': 0.0
        },
        {
            'query': 'æˆ‘æ˜¯75å¹´çš„å¥³èŒå·¥ï¼Œäº¤äº†5å¹´ç¤¾ä¿ï¼Œèƒ½é€€ä¼‘å—ï¼Ÿ',
            'type': 'å¤æ‚é—®é¢˜',
            'sub_questions': [
                "å¥³èŒå·¥é€€ä¼‘å¹´é¾„æ˜¯å¤šå°‘ï¼Ÿ",
                "ç¤¾ä¿ç¼´è´¹å¹´é™è¦æ±‚æ˜¯å¤šå°‘ï¼Ÿ",
                "75å¹´å‡ºç”Ÿç°åœ¨å¤šå°‘å²ï¼Ÿ"
            ],
            'bm25': 15.0, 'overlap': 0.2, 'top3': 0.0
        },
    ]
    
    print("\nã€æµ‹è¯•æ¨¡å¼: æ¨¡æ‹Ÿå­é—®é¢˜ï¼ˆä¸ä½¿ç”¨LLMï¼‰ã€‘")
    print("=" * 100)
    
    for i, case in enumerate(test_cases, 1):
        query = case['query']
        sub_questions = case['sub_questions']
        
        print(f"\n{'-'*100}")
        print(f"æµ‹è¯• {i}: {case['type']}")
        print(f"{'-'*100}")
        print(f"æŸ¥è¯¢: {query}")
        
        # è¯„ä¼°5ä¸ªç»´åº¦
        result = calculate_five_dimension_score(
            query=query,
            sub_questions=sub_questions,
            bm25_top1_score=case['bm25'],
            overlap_ratio=case['overlap'],
            top3_overlap=case['top3']
        )
        
        print(f"\nã€å­é—®é¢˜ã€‘({len(sub_questions)}ä¸ª)")
        for j, sq in enumerate(sub_questions, 1):
            print(f"  {j}. {sq}")
        
        print(f"\nã€5ä¸ªç»´åº¦è¯„ä¼°ã€‘")
        print(f"  1. æ¨ç†é“¾é•¿åº¦: {result['dimension_1_reasoning_chain']['score']:.3f} - {result['dimension_1_reasoning_chain']['level']}")
        print(f"  2. çŸ¥è¯†æ•´åˆéœ€æ±‚: {result['dimension_2_knowledge_integration']['score']:.3f} - {result['dimension_2_knowledge_integration']['level']}")
        print(f"  3. å…³ç³»æ¨ç†å¤æ‚åº¦: {result['dimension_3_relational_reasoning']['score']:.3f} - {result['dimension_3_relational_reasoning']['level']}")
        print(f"  4. é¢†åŸŸè·¨åº¦: {result['dimension_4_domain_span']['score']:.3f} - {result['dimension_4_domain_span']['level']}")
        print(f"  5. æ¡ä»¶çº¦æŸå¯†åº¦: {result['dimension_5_conditional_constraint']['score']:.3f} - {result['dimension_5_conditional_constraint']['level']}")
        
        print(f"\nã€ç»´åº¦è¦†ç›–ã€‘")
        print(f"  è¦†ç›–ç»´åº¦æ•°: {result['num_covered_dimensions']}/5")
        print(f"  è¦†ç›–ç»´åº¦: {', '.join(result['covered_dimensions']) if result['covered_dimensions'] else 'æ— '}")
        
        print(f"\nã€ç»¼åˆè¯„åˆ†ã€‘")
        print(f"  é—®é¢˜æœ¬è´¨å¤æ‚åº¦: {result['question_complexity']:.3f}")
        print(f"  æ£€ç´¢ä¸€è‡´æ€§ç½®ä¿¡åº¦: {result['retrieval_consistency']['score']:.3f}")
        print(f"  æœ€ç»ˆè¯„åˆ†: {result['final_score']:.3f}")
        
        print(f"\nã€å†³ç­–ç»“æœã€‘")
        print(f"  æ˜¯å¦éœ€è¦KG: {'æ˜¯' if result['needs_kg'] else 'å¦'}")
        print(f"  å†³ç­–ç†ç”±: {result['reason']}")
    
    print(f"\n{'='*100}")
    print("æµ‹è¯•å®Œæˆ")
    print("="*100)
    print("\næç¤ºï¼šå®é™…ä½¿ç”¨æ—¶ï¼Œå­é—®é¢˜åº”è¯¥ç”±LLMè‡ªåŠ¨ç”Ÿæˆã€‚")
    print("è¯·åœ¨ä¸»è„šæœ¬ä¸­è°ƒç”¨ calculate_combined_score_with_simplicity() å¹¶ä¼ å…¥LLMå®ä¾‹ã€‚")


if __name__ == "__main__":
    import sys
    
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1 and sys.argv[1] == '--old':
        # è¿è¡Œæ—§çš„æµ‹è¯•ï¼ˆå¤šè·³+å±‚çº§ï¼‰
        print("è¿è¡Œæ—§ç‰ˆæµ‹è¯•ï¼ˆå¤šè·³æ¨ç†+å±‚çº§ç»“æ„ï¼‰...\n")
        # æ—§æµ‹è¯•ä»£ç å·²ç»åœ¨ä¸Šé¢å®šä¹‰
    else:
        # é»˜è®¤è¿è¡Œæ–°çš„æµ‹è¯•ï¼ˆ5ç»´åº¦ï¼‰
        test_five_dimensions()
