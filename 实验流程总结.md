# 混合RAG法律问答系统实验流程总结

## 📋 项目概述

本项目实现了一个基于混合检索策略的法律问答系统，结合了**向量检索**、**BM25文本检索**和**知识图谱检索**三种方法，通过智能判断查询复杂度来动态选择最优检索策略。

### 核心特性
- ✅ 混合检索：语义向量检索 + BM25文本检索
- ✅ 智能路由：基于检索结果相似度自动判断是否需要知识图谱
- ✅ 法条精确匹配：对法条查询进行特殊优化
- ✅ 重排序优化：使用BGE-reranker对检索结果重排序
- ✅ 动态文档选择：根据查询复杂度自适应选择文档数量

---


## 🔍 检索与问答流程

### 2. 核心检索系统

**主脚本**: `hybrid_rag_query.py`

#### 2.0 混合检索使用流程图

```
查询输入
    ↓
步骤1: 语义检索 → semantic_results (Top-10)
    ↓
步骤2: BM25检索 → bm25_results (Top-10)
    ↓
步骤3: 计算相似度指标 → combined_score
    ↓
步骤4: 创建混合检索结果
    ├─ 合并两种检索结果
    ├─ 归一化分数
    ├─ 计算混合分数 (0.7*语义 + 0.3*BM25)
    └─ 按混合分数排序 → hybrid_results
    ↓
步骤4.5: 重排序与动态选择
    ├─ 使用reranker重排序 hybrid_results
    └─ 根据查询复杂度选择文档数量 → reranked_results
    ↓
步骤5: 生成答案
    ├─ 简单查询: 使用 reranked_results
    └─ 复杂查询: 使用 reranked_results + 知识图谱
    ↓
最终答案
```


##### 步骤0: 查询重写
**目的**: 提高检索召回率和一致性

**策略**:
- 简单查询：规则重写（提取关键词）
- 复杂查询：LLM重写（扩展语义）

```python
rewritten_query = rewrite_query_for_consistency(query, instruction)
```

##### 步骤1: 语义向量检索
**方法**: 使用BGE-M3模型进行语义相似度检索

```python
semantic_results = semantic_search(query, top_k=10)
```

**返回**: Top-10最相似的法条文档

##### 步骤2: BM25文本检索
**方法**: 基于词频的文本相似度检索

```python
bm25_results = bm25_search(query, top_k=10)
```

**特点**: 
- 对关键词匹配敏感
- 适合精确法条查询

##### 步骤3: 多维度相似度计算
**目的**: 评估两种检索方法的一致性

**核心指标**:

1. **BM25 Top1分数** (bm25_top1_score)
   - **计算方式**: 
     ```python
     bm25_top1_score = bm25_results[0]['bm25_score']
     ```
   - **取值范围**: 0 ~ 10+ (无上限，但通常在0-20之间)
   - **物理意义**: 
     - 衡量查询词与文档的关键词匹配程度
     - **高分 (>12)**: 查询包含明确关键词，精确匹配效果好
     - **低分 (<8)**: 查询抽象或关键词少，需要语义理解
   - **实际应用**: 
     - 法条查询："第三条" → 高分 (15-20)
     - 概念查询："工会的作用" → 低分 (3-8)

2. **文档重叠率** (overlap_ratio)
   - **计算方式**:
     ```python
     overlap_ids = set(semantic_ids) & set(bm25_ids)
     overlap_ratio = len(overlap_ids) / len(semantic_ids)
     ```
   - **取值范围**: 0.0 ~ 1.0
   - **物理意义**:
     - 衡量两种检索方法返回的文档集合的相似程度
     - **高重叠 (>0.6)**: 两种方法找到相同文档，结果一致
     - **低重叠 (<0.3)**: 两种方法找到不同文档，结果差异大
   - **实际应用**:
     - 简单查询：重叠率低（语义找不到，BM25精确匹配）
     - 复杂查询：重叠率高（都找不到精确答案，返回相似文档）

3. **Top-3重叠率** (top3_overlap)
   - **计算方式**:
     ```python
     top3_semantic = set(semantic_ids[:3])
     top3_bm25 = set(bm25_ids[:3])
     top3_overlap = len(top3_semantic & top3_bm25) / 3
     ```
   - **取值范围**: 0.0 ~ 1.0
   - **物理意义**:
     - 关注最相关的Top-3文档的一致性
     - 比整体重叠率更关注高质量结果
     - **高重叠**: 两种方法对最相关文档的判断一致
     - **低重叠**: 两种方法对最相关文档的判断不同

4. **综合相似度** (combined_score)
   - **计算方式**: 使用竞争函数（详见下文）
   - **取值范围**: 0.0 ~ 1.0
   - **物理意义**: 
     - 系统对"这是简单问题"的置信度
     - **高分 (≥0.70)**: 高度确信是简单问题，使用混合检索
     - **低分 (<0.70)**: 高度确信是复杂问题，需要知识图谱
   - **核心决策依据**: 智能路由的阈值判断

---

#### 综合相似度的计算方法（竞争函数）

**核心思想**: 通过"查询简单性"和"检索一致性"两个维度，计算系统对"这是简单问题"的置信度。

##### 第一步: 计算查询简单性指数 (QSI)

**公式**:
```python
QSI = 1 / (1 + e^(0.5 × (BM25_Top1 - 12.5)))
```

**物理意义**:
- 使用Sigmoid函数将BM25分数映射到[0,1]
- BM25分数越低 → QSI越高 → 查询越简单
- 中心点12.5：BM25=12.5时，QSI=0.5


##### 第二步: 计算检索差异性指数 (RDI)

**公式**:
```python
RDI = 1 - (0.7 × overlap_ratio + 0.3 × top3_overlap)
```

**物理意义**:
- 重叠率越低 → RDI越高 → 两种方法差异越大
- 权重: 整体重叠70% + Top3重叠30%

**⚠️ 反直觉的关键洞察：为什么差异大 = 简单问题？**

这是整个系统最反直觉但最重要的设计！让我们用实际例子说明：

**场景1: 简单法条查询（差异大 = 简单）**
```
查询: "《工会法》第三条的内容是什么？"

BM25检索:
✅ Top1: 《工会法》第三条 (精确匹配"第三条")
   Top2: 《工会法》第五十一条 (包含"第三条"关键词)
   Top3: 《工会法》第十二条

语义检索:
❌ Top1: 《工会法》第二条 (语义相关但不是第三条)
   Top2: 《工会法》第四条 (语义相关但不是第三条)
   Top3: 《工会法》第一条

重叠率: 0.0 (完全不重叠)
RDI = 1.0 (差异极大)

解释:
- BM25精确匹配到了正确答案（第三条）
- 语义检索理解了"内容"，但找不到精确的"第三条"
- 两种方法结果完全不同 → 说明BM25有效，语义失败
- 结论: 这是简单问题，混合检索（BM25权重高）即可
```

**场景2: 复杂推理查询（差异小 = 复杂）**
```
查询: "劳动者在什么情况下可以单方面解除劳动合同？"

BM25检索:
   Top1: 《劳动合同法》第三十七条 (包含关键词)
   Top2: 《劳动合同法》第三十八条 (包含关键词)
   Top3: 《劳动合同法》第三十九条

语义检索:
   Top1: 《劳动合同法》第三十八条 (语义理解)
   Top2: 《劳动合同法》第三十七条 (语义理解)
   Top3: 《劳动合同法》第四十条

重叠率: 0.7 (高度重叠)
RDI = 0.3 (差异小)

解释:
- 两种方法都找到了相关法条
- 但都不够精确，需要理解多个法条的关系
- 两种方法结果相似 → 说明都找不到精确答案
- 结论: 这是复杂问题，需要知识图谱推理
```

**核心原理总结**:

```
检索差异大 (RDI高):
→ 一种方法成功，另一种失败
→ 说明问题有明确答案，某种方法能精确匹配
→ 简单问题

检索差异小 (RDI低):
→ 两种方法都返回相似的模糊结果
→ 说明问题没有明确答案，都在"猜测"
→ 复杂问题，需要更强的推理
```

**类比理解**:

想象你在找一本书：

| 场景 | 关键词匹配 | 语义理解 | 结果差异 | 问题类型 |
|------|----------|---------|---------|---------|
| "我要《红楼梦》" | 找到《红楼梦》✅ | 推荐《西游记》❌ | 大 | 简单（精确书名） |
| "介绍家族制度的书" | 找到相关书籍 | 找到相关书籍 | 小 | 复杂（需求模糊） |

**实例**:
| overlap_ratio | top3_overlap | RDI | 解释 |
|--------------|--------------|-----|------|
| 0.1 | 0.0 | 0.93 | 差异极大（BM25精确，语义失败）→ 简单 |
| 0.3 | 0.33 | 0.69 | 差异较大 → 较简单 |
| 0.5 | 0.67 | 0.45 | 差异中等 → 边界情况 |
| 0.8 | 1.0 | 0.14 | 差异很小（都找不到精确答案）→ 复杂 |

##### 第三步: 计算简单问题置信度 (SCS)

**公式** (竞争函数):
```python
# 简单问题的证据强度
simple_evidence = QSI^α × RDI^β

# 复杂问题的证据强度
complex_evidence = (1-QSI)^α × (1-RDI)^β

# 归一化得到置信度
SCS = simple_evidence / (simple_evidence + complex_evidence)
```

**参数**:
- α = 1.5 (QSI的权重指数)
- β = 0.3 (RDI的权重指数)

**物理意义**:
- 类似Softmax的二分类版本
- 分子：简单问题的"证据强度"
- 分母：简单问题证据 + 复杂问题证据
- 结果：系统对"这是简单问题"的置信度

**后处理惩罚**:
```python
# 当BM25较高且overlap较低时，强制降低置信度
if bm25_top1 > 10.0 and overlap_ratio < 0.3:
    bm25_penalty = min(0.95, (bm25_top1 - 10.0) / 6.0)
    overlap_bonus = overlap_ratio / 0.3
    final_penalty = bm25_penalty * (1.0 - overlap_bonus)
    SCS = SCS * (1.0 - final_penalty)
```

**原因**: 高BM25 + 低重叠 通常表示复杂问题（关键词多但都找不到精确答案）

##### 实际案例分析

**案例1: 简单法条查询**
```
查询: "《中华人民共和国工会法》第三条的内容是什么？"

指标值:
- BM25 Top1: 18.5 → QSI = 0.12 (低)
- overlap_ratio: 0.2 → 
- top3_overlap: 0.0 →
- RDI = 1 - (0.7×0.2 + 0.3×0.0) = 0.86 (高)

计算:
- simple_evidence = 0.12^1.5 × 0.86^0.3 = 0.041 × 0.956 = 0.039
- complex_evidence = 0.88^1.5 × 0.14^0.3 = 0.826 × 0.673 = 0.556
- SCS = 0.039 / (0.039 + 0.556) = 0.065

后处理惩罚:
- bm25_penalty = (18.5-10)/6 = 1.42 → 0.95 (上限)
- overlap_bonus = 0.2/0.3 = 0.67
- final_penalty = 0.95 × (1-0.67) = 0.31
- 最终SCS = 0.065 × (1-0.31) = 0.045

结论: SCS = 0.045 < 0.70 → 判断为复杂问题 → 使用知识图谱
```

**案例2: 概念查询**
```
查询: "工会的主要职责是什么？"

指标值:
- BM25 Top1: 6.5 → QSI = 0.95 (高)
- overlap_ratio: 0.6 →
- top3_overlap: 0.67 →
- RDI = 1 - (0.7×0.6 + 0.3×0.67) = 0.38 (中)

计算:
- simple_evidence = 0.95^1.5 × 0.38^0.3 = 0.926 × 0.783 = 0.725
- complex_evidence = 0.05^1.5 × 0.62^0.3 = 0.011 × 0.877 = 0.010
- SCS = 0.725 / (0.725 + 0.010) = 0.986

结论: SCS = 0.986 > 0.70 → 判断为简单问题 → 使用混合检索
```

---

##### 步骤4: 混合检索与智能路由
**混合策略**: 加权融合两种检索结果

```python
# 对每个文档计算混合分数
hybrid_score = alpha * semantic_score_norm + (1 - alpha) * bm25_score_norm
# 推荐 alpha = 0.7 (70%语义 + 30%BM25)
```

**混合检索过程**:
1. 合并两种检索的所有文档（去重）
2. 对语义分数和BM25分数分别归一化到[0,1]
3. 按混合分数重新排序
4. 输出混合检索结果 `hybrid_results`

**重要**: 混合检索结果会在后续步骤中被使用！

**智能路由决策**:

| 综合相似度 | 判断 | 策略 |
|-----------|------|------|
| ≥ 0.70 | 简单查询 | 使用混合检索结果（重排序后） |
| < 0.70 | 复杂查询 | 混合检索结果 + 知识图谱 |

**阈值说明**:
- 简单问题平均分: 0.878
- 复杂问题平均分: 0.370
- 区分度: 0.508
- 选择阈值: 0.70（平衡准确率和召回率）

##### 步骤4.5: 重排序与动态文档选择
**输入**: 步骤4的混合检索结果 `hybrid_results`

**重排序**: 使用BGE-reranker-v2-m3对混合结果重排序

```python
# 使用reranker模型对混合检索结果重新打分
reranked_results = reranker.rank(query, hybrid_results)
```

**动态选择策略**:
```python
if is_simple_query:
    # 简单查询：选择高置信度文档（score > 0.5）
    selected_docs = [doc for doc in docs if doc.score > 0.5]
    min_docs = 1  # 至少1个
    max_docs = 3  # 最多3个
else:
    # 复杂查询：选择更多文档
    selected_docs = [doc for doc in docs if doc.score > 0.3]
    min_docs = 3  # 至少3个
    max_docs = 5  # 最多5个
```

**输出**: 重排序并筛选后的结果 `reranked_results`

**关键点**: 
- 重排序基于混合检索结果，不是单独的语义或BM25结果
- 动态选择确保简单查询使用少量高质量文档，复杂查询使用更多文档

##### 步骤5: 答案生成

**输入**: 
- 重排序后的混合检索结果 `reranked_results`
- 原始的语义和BM25结果（用于法条精确匹配）

**上下文构建**:

**简单查询** (综合相似度 ≥ 0.70):
```python
# 直接使用重排序后的混合检索结果
final_context = "\n\n".join([
    f"【文档{i+1}】{r['source_name']}\n{r['text']}"
    for i, r in enumerate(reranked_results)
])
```

**复杂查询** (综合相似度 < 0.70):
```python
# 融合混合检索结果和知识图谱
vector_context = "\n\n".join([...reranked_results...])
kg_context = kg_search(query)

final_context = f"""
## 向量检索结果
{vector_context}

## 知识图谱检索结果
{kg_context}
"""
```

**关键点**: 
- 无论简单还是复杂查询，都使用了混合检索的重排序结果
- 复杂查询额外增加知识图谱信息

**法条查询特殊处理**:

1. **精确匹配优先**（新增优化）
   - 检测查询是否包含"第XX条"
   - 在检索结果中精确匹配法条
   - 匹配策略：
     - 优先级1: 精确匹配`source_name`
     - 优先级2: 模糊匹配`source_name`
     - 优先级3: 匹配`text`字段
   - 找到后直接返回，不经过LLM

2. **LLM生成**（精确匹配失败时）
   - 使用严格的提示词
   - 明确指定目标法条
   - 要求只返回指定法条



## 📊 实验评估

### 4. 评估指标体系

#### 4.1 检索质量指标（核心指标）

本系统使用4个核心指标来评估检索质量和判断查询复杂度：

##### 指标1: BM25 Top1分数

**定义**: BM25检索结果中第一个文档的分数

**计算公式**:
```python
bm25_top1_score = bm25_results[0]['bm25_score']

# BM25分数计算（rank_bm25库）
BM25(q,d) = Σ IDF(qi) × (f(qi,d) × (k1+1)) / (f(qi,d) + k1 × (1-b+b×|d|/avgdl))
```
其中:
- q: 查询词
- d: 文档
- f(qi,d): 词qi在文档d中的频率
- IDF(qi): 逆文档频率
- k1=1.5, b=0.75: BM25参数
- |d|: 文档长度
- avgdl: 平均文档长度

**取值范围**: 0 ~ 无上限（通常0-25）

**物理意义**:
- 衡量查询词与文档的**关键词匹配程度**
- 考虑词频、文档长度、逆文档频率
- 分数越高，关键词匹配越精确

**分数解读**:
| 分数区间 | 匹配程度 | 典型场景 |
|---------|---------|---------|
| 0-5 | 弱匹配 | 抽象概念查询，关键词少 |
| 5-10 | 中等匹配 | 一般查询 |
| 10-15 | 强匹配 | 包含明确关键词 |
| 15-20 | 非常强匹配 | 精确法条查询（"第XX条"） |
| >20 | 极强匹配 | 长查询，多个关键词精确匹配 |

**实际案例**:
```python
# 案例1: 法条查询
query = "《中华人民共和国工会法》第三条的内容是什么？"
bm25_top1_score = 18.5  # 高分，精确匹配"工会法"、"第三条"

# 案例2: 概念查询
query = "工会的主要职责是什么？"
bm25_top1_score = 6.5   # 低分，只匹配"工会"、"职责"

# 案例3: 推理查询
query = "劳动者在什么情况下可以解除劳动合同？"
bm25_top1_score = 12.3  # 中等，匹配"劳动者"、"劳动合同"
```

---

##### 指标2: 文档重叠率

**定义**: 语义检索和BM25检索返回的文档集合的交集比例

**计算公式**:
```python
semantic_ids = [r['hash_code'] for r in semantic_results]
bm25_ids = [r['hash_code'] for r in bm25_results]
overlap_ids = set(semantic_ids) & set(bm25_ids)
overlap_ratio = len(overlap_ids) / len(semantic_ids)
```

**取值范围**: 0.0 ~ 1.0

**物理意义**:
- 衡量两种检索方法的**结果一致性**
- 高重叠：两种方法找到相同文档
- 低重叠：两种方法找到不同文档

**重叠率解读**:
| 重叠率 | 一致性 | 含义 | 典型场景 |
|-------|-------|------|---------|
| 0.0-0.2 | 极低 | 两种方法完全不同 | 简单法条查询（BM25精确，语义失败） |
| 0.2-0.4 | 低 | 两种方法差异大 | 一般简单查询 |
| 0.4-0.6 | 中等 | 两种方法部分一致 | 边界情况 |
| 0.6-0.8 | 高 | 两种方法基本一致 | 复杂查询（都找不到精确答案） |
| 0.8-1.0 | 极高 | 两种方法完全一致 | 非常复杂的推理查询 |

**为什么低重叠表示简单问题？**

这是一个反直觉但关键的洞察：

**传统直觉（错误）**:
```
❌ 两种方法结果一致 → 都对 → 简单问题
❌ 两种方法结果不同 → 都不确定 → 复杂问题
```

**实际情况（正确）**:
```
✅ 两种方法结果不同 → 一种精确匹配，一种失败 → 简单问题
✅ 两种方法结果相同 → 都找不到精确答案 → 复杂问题
```

**详细解释**:

**简单问题（如法条查询）**:
```
查询: "《工会法》第三条的内容"

BM25检索:
- 精确匹配"第三条"关键词
- 直接找到《工会法》第三条 ✅ 正确答案

语义检索:
- 理解"内容是什么"的语义
- 找到语义相关的其他法条（第二条、第四条等）
- 但找不到精确的"第三条" ❌ 错误答案

结果: 
- 重叠率低（两种方法找到不同文档）
- BM25有效，语义失败
- 说明问题有明确答案，BM25能精确匹配
- 结论: 简单问题，使用混合检索（BM25权重高）即可
```

**复杂问题（如推理查询）**:
```
查询: "劳动者在什么情况下可以解除劳动合同？"

BM25检索:
- 匹配"劳动者"、"解除"、"劳动合同"关键词
- 找到包含这些词的多个法条
- 但不知道哪个是最准确的答案 ❓

语义检索:
- 理解"什么情况下可以解除"的语义
- 找到语义相关的多个法条
- 也不知道哪个是最准确的答案 ❓

结果:
- 重叠率高（两种方法找到相似的文档）
- 都找不到精确答案，都在"猜测"
- 说明问题需要理解多个法条的关系和适用条件
- 结论: 复杂问题，需要知识图谱进行推理
```

**核心原理**:

| 重叠率 | 含义 | 问题类型 | 原因 |
|-------|------|---------|------|
| 低 (0.0-0.3) | 两种方法结果不同 | 简单 | 一种精确匹配成功，另一种失败 |
| 中 (0.3-0.6) | 两种方法部分一致 | 边界 | 不确定 |
| 高 (0.6-1.0) | 两种方法结果相似 | 复杂 | 都找不到精确答案，返回相似文档 |

**类比**:

```
场景: 两个医生诊断同一个病人

情况1（简单病症）:
- 医生A（经验丰富）: "这是感冒，吃感冒药"
- 医生B（刚毕业）: "可能是流感，也可能是过敏"
- 诊断差异大 → 说明A有把握，B不确定 → 简单病症

情况2（复杂病症）:
- 医生A: "可能是A病，也可能是B病，需要进一步检查"
- 医生B: "可能是A病，也可能是C病，需要进一步检查"
- 诊断相似 → 说明都不确定 → 复杂病症，需要专家会诊
```

---

##### 指标3: Top-3重叠率

**定义**: 两种检索方法Top-3结果的交集比例

**计算公式**:
```python
top3_semantic = set(semantic_ids[:3])
top3_bm25 = set(bm25_ids[:3])
top3_overlap = len(top3_semantic & top3_bm25)
top3_overlap_ratio = top3_overlap / 3
```

**取值范围**: 0.0 ~ 1.0 (离散值: 0, 0.33, 0.67, 1.0)

**物理意义**:
- 关注**最相关文档**的一致性
- 比整体重叠率更关注高质量结果
- Top-3通常是最终答案的主要来源

**为什么需要Top-3重叠率？**

整体重叠率可能受到低相关文档的影响，Top-3重叠率更关注核心结果：

```python
# 案例: 整体重叠高，但Top-3不同
semantic_ids = [A, B, C, D, E, F, G, H, I, J]
bm25_ids =     [X, Y, Z, D, E, F, G, H, I, J]

overlap_ratio = 7/10 = 0.7  # 高重叠
top3_overlap = 0/3 = 0.0    # Top-3完全不同

# 解释: 虽然整体重叠高，但最相关的Top-3完全不同
# 说明两种方法对"最佳答案"的判断不一致
```

---

##### 指标4: 综合相似度（置信度分数）

**定义**: 系统对"这是简单问题"的置信度

**计算方法**: 见上文"综合相似度的计算方法（竞争函数）"

**取值范围**: 0.0 ~ 1.0

**物理意义**:
- **高分 (≥0.70)**: 高度确信是简单问题
  - 查询简单（低BM25）+ 检索差异大（低重叠）
  - 使用混合检索即可
  
- **低分 (<0.70)**: 高度确信是复杂问题
  - 查询复杂（高BM25）+ 检索相似（高重叠）
  - 需要知识图谱辅助

**阈值选择**:
- 阈值 = 0.70
- 简单问题平均分: 0.878
- 复杂问题平均分: 0.370
- 区分度: 0.508

---

#### 4.2 答案质量指标

评估生成答案的质量：

##### 准确率
- **定义**: 答案是否正确
- **计算**: 人工标注或自动评估（与标准答案对比）

##### 完整性
- **定义**: 是否包含完整法条内容
- **评估**: 检查是否遗漏关键信息

##### 格式规范
- **定义**: 是否符合格式要求
- **标准**: `《法律名称》第XX条: [法条原文]`

---

#### 4.3 系统性能指标

##### 知识图谱使用率
- **定义**: 使用知识图谱的查询占比
- **计算**: `kg_used_count / total_queries`
- **意义**: 反映复杂查询的比例

##### 平均响应时间
- **定义**: 从查询到返回答案的平均时间
- **分类**:
  - 精确匹配: < 0.2秒
  - 混合检索: 0.5-2秒
  - 知识图谱: 2-5秒

##### 精确匹配成功率
- **定义**: 法条查询中精确匹配成功的比例
- **计算**: `exact_match_count / law_article_queries`
- **目标**: > 95%

---

### 4.4 指标之间的关系

#### 相关性分析

```
BM25分数 ↑ → QSI ↓ → 综合相似度 ↓
重叠率 ↑ → RDI ↓ → 综合相似度 ↓

简单问题特征:
- 低BM25 (< 10) + 低重叠 (< 0.3) → 高综合相似度 (> 0.8)

复杂问题特征:
- 高BM25 (> 15) + 高重叠 (> 0.6) → 低综合相似度 (< 0.4)

边界情况:
- 中BM25 (10-15) + 中重叠 (0.3-0.6) → 中综合相似度 (0.4-0.8)
```

#### 决策流程

```
输入: 查询
  ↓
计算: BM25分数、重叠率、Top3重叠
  ↓
计算: QSI、RDI
  ↓
计算: 综合相似度（竞争函数）
  ↓
判断: 综合相似度 vs 阈值(0.70)
  ↓
输出: 简单问题 or 复杂问题
  ↓
策略: 混合检索 or 混合检索+知识图谱
```

---

### 5. 评估数据集

**输入文件**: `datasets/query_social_hybrid_pred_metrics_v2.json`

**数据格式**:
```json
{
  "instruction": "回答以下问题，只需直接给出法条内容...",
  "question": "《中华人民共和国工会法》第三条的内容是什么？",
  "answer": "答案:在中国境内的企业、事业单位...",
  "prediction": "《中华人民共和国工会法》第三条: ...",
  "bm25_top1_score": 8.009,
  "overlap_ratio": 0.2,
  "top3_overlap": 0.0,
  "combined_score": 0.980,
  "used_kg": false,
  "elapsed_time": 0.181
}
```

### 4. 评估指标

#### 4.1 检索质量指标
- **BM25 Top1分数**: 关键词匹配质量
- **文档重叠率**: 检索一致性
- **Top-3重叠率**: 高相关文档一致性
- **综合相似度**: 整体检索质量

#### 4.2 答案质量指标
- **准确率**: 答案是否正确
- **完整性**: 是否包含完整法条内容
- **格式规范**: 是否符合格式要求

#### 4.3 系统性能指标
- **知识图谱使用率**: 复杂查询占比
- **平均响应时间**: 系统效率
- **精确匹配成功率**: 法条查询优化效果

---



---

## 🎯 混合检索的核心作用（重要说明）

### 问题：混合检索结果真的被使用了吗？

**答案：是的！混合检索是整个系统的核心。**

### 为什么需要混合检索？

**单一检索方法的局限**:
- **语义检索**：理解语义，但可能忽略关键词（如法条编号）
- **BM25检索**：精确匹配关键词，但缺乏语义理解

**混合检索的优势**:
融合两者优势，在不同场景下都能表现良好：
- 法条查询：BM25权重帮助精确匹配"第XX条"
- 概念查询：语义权重帮助理解抽象概念
- 推理查询：混合结果提供更全面的上下文

### 混合检索在流程中的使用

#### 步骤4: 创建混合检索结果
```python
# 对每个文档计算混合分数
hybrid_score = 0.7 * semantic_score_norm + 0.3 * bm25_score_norm

# 按混合分数重新排序
hybrid_results = sorted(all_docs, key=lambda x: x['hybrid_score'], reverse=True)
```

**输出**: `hybrid_results` (混合检索结果)

#### 步骤4.5: 重排序优化
```python
# 使用reranker对混合检索结果重排序
reranked_results = reranker.rank(query, hybrid_results)

# 动态选择文档数量
selected_results = select_by_confidence(reranked_results, is_simple)
```

**输入**: `hybrid_results` (步骤4的输出)  
**输出**: `reranked_results` (重排序后的混合结果)

#### 步骤5: 答案生成
```python
# 简单查询
if combined_score >= 0.70:
    final_context = format_context(reranked_results)  # 使用混合检索的重排序结果
    
# 复杂查询
else:
    vector_context = format_context(reranked_results)  # 使用混合检索的重排序结果
    kg_context = kg_search(query)
    final_context = vector_context + kg_context
```

